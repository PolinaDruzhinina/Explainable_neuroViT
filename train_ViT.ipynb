{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e1c2e181-f2ad-4bb3-8583-796317016f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MINIT.minit import MINiT\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bc811d6-933d-49c4-8921-df5e1513e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1301/9726765.py:2: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  adni_merge_2 = pd.read_csv('ADNIMERGE.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "adni_merge_1 = pd.read_csv('our_subj_adnimerge.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n",
    "adni_merge_2 = pd.read_csv('ADNIMERGE.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n",
    "adni_merge_1 = adni_merge_1[['PTID', 'VISCODE', 'DX_bl']]\n",
    "adni_merge_2 = adni_merge_2[['PTID', 'VISCODE', 'DX_bl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d6a83d0-f4d0-4a62-9c7b-54774fad90ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1301/2513726996.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Counter(pd.read_csv('ADNIMERGE.csv')['DX_bl'].values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'CN': 4512,\n",
       "         'AD': 1667,\n",
       "         'LMCI': 5037,\n",
       "         'SMC': 1037,\n",
       "         'EMCI': 2740,\n",
       "         nan: 10})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# какое количество классов во всем ADNI\n",
    "from collections import Counter\n",
    "Counter(pd.read_csv('ADNIMERGE.csv')['DX_bl'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "457a5647-8a62-4a08-839b-ac78114a852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1301/4009778700.py:1: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>PTID</th>\n",
       "      <th>VISCODE</th>\n",
       "      <th>SITE</th>\n",
       "      <th>COLPROT</th>\n",
       "      <th>ORIGPROT</th>\n",
       "      <th>EXAMDATE</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>...</th>\n",
       "      <th>TAU_bl</th>\n",
       "      <th>PTAU_bl</th>\n",
       "      <th>FDG_bl</th>\n",
       "      <th>PIB_bl</th>\n",
       "      <th>AV45_bl</th>\n",
       "      <th>Years_bl</th>\n",
       "      <th>Month_bl</th>\n",
       "      <th>Month</th>\n",
       "      <th>M</th>\n",
       "      <th>update_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-08</td>\n",
       "      <td>CN</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-09 04:20:17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>bl</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-09 04:20:17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>m06</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2006-03-13</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498289</td>\n",
       "      <td>5.96721</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2020-03-25 15:43:58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>m12</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>11.96720</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020-01-09 04:20:17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>011_S_0003</td>\n",
       "      <td>m24</td>\n",
       "      <td>11</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>ADNI1</td>\n",
       "      <td>2007-09-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>81.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>239.7</td>\n",
       "      <td>22.83</td>\n",
       "      <td>1.08355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.998630</td>\n",
       "      <td>23.93440</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-01-09 04:20:17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>6309</td>\n",
       "      <td>114_S_6309</td>\n",
       "      <td>m24</td>\n",
       "      <td>114</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>SMC</td>\n",
       "      <td>65.2</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0199</td>\n",
       "      <td>2.379190</td>\n",
       "      <td>28.49180</td>\n",
       "      <td>30</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-11-06 04:21:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>6385</td>\n",
       "      <td>024_S_6385</td>\n",
       "      <td>m24</td>\n",
       "      <td>24</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>CN</td>\n",
       "      <td>66.6</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.414780</td>\n",
       "      <td>28.91800</td>\n",
       "      <td>30</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-11-06 04:21:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>6574</td>\n",
       "      <td>941_S_6574</td>\n",
       "      <td>m24</td>\n",
       "      <td>941</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>CN</td>\n",
       "      <td>73.5</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.108140</td>\n",
       "      <td>25.24590</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-11-06 04:21:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15001</th>\n",
       "      <td>6575</td>\n",
       "      <td>941_S_6575</td>\n",
       "      <td>m24</td>\n",
       "      <td>941</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>CN</td>\n",
       "      <td>73.5</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.108140</td>\n",
       "      <td>25.24590</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-11-06 04:21:15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15002</th>\n",
       "      <td>6222</td>\n",
       "      <td>037_S_6222</td>\n",
       "      <td>m24</td>\n",
       "      <td>37</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>ADNI3</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>73.9</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.22133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.299790</td>\n",
       "      <td>27.54100</td>\n",
       "      <td>30</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2020-11-07 04:57:56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15003 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RID        PTID VISCODE  SITE COLPROT ORIGPROT    EXAMDATE DX_bl  \\\n",
       "0         2  011_S_0002      bl    11   ADNI1    ADNI1  2005-09-08    CN   \n",
       "1         3  011_S_0003      bl    11   ADNI1    ADNI1  2005-09-12    AD   \n",
       "2         3  011_S_0003     m06    11   ADNI1    ADNI1  2006-03-13    AD   \n",
       "3         3  011_S_0003     m12    11   ADNI1    ADNI1  2006-09-12    AD   \n",
       "4         3  011_S_0003     m24    11   ADNI1    ADNI1  2007-09-12    AD   \n",
       "...     ...         ...     ...   ...     ...      ...         ...   ...   \n",
       "14998  6309  114_S_6309     m24   114   ADNI3    ADNI3  2020-10-27   SMC   \n",
       "14999  6385  024_S_6385     m24    24   ADNI3    ADNI3  2020-11-05    CN   \n",
       "15000  6574  941_S_6574     m24   941   ADNI3    ADNI3  2020-10-27    CN   \n",
       "15001  6575  941_S_6575     m24   941   ADNI3    ADNI3  2020-10-27    CN   \n",
       "15002  6222  037_S_6222     m24    37   ADNI3    ADNI3  2020-11-02  EMCI   \n",
       "\n",
       "        AGE PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  \\\n",
       "0      74.3     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   \n",
       "1      81.3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   \n",
       "2      81.3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   \n",
       "3      81.3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316   \n",
       "4      81.3     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630   \n",
       "...     ...      ...  ...     ...     ...      ...    ...      ...       ...   \n",
       "14998  65.2   Female  ...     NaN     NaN      NaN    NaN   1.0199  2.379190   \n",
       "14999  66.6   Female  ...     NaN     NaN      NaN    NaN      NaN  2.414780   \n",
       "15000  73.5   Female  ...     NaN     NaN      NaN    NaN      NaN  2.108140   \n",
       "15001  73.5     Male  ...     NaN     NaN      NaN    NaN      NaN  2.108140   \n",
       "15002  73.9   Female  ...     NaN     NaN  1.22133    NaN      NaN  2.299790   \n",
       "\n",
       "       Month_bl  Month     M           update_stamp  \n",
       "0       0.00000      0   0.0  2020-01-09 04:20:17.0  \n",
       "1       0.00000      0   0.0  2020-01-09 04:20:17.0  \n",
       "2       5.96721      6   6.0  2020-03-25 15:43:58.0  \n",
       "3      11.96720     12  12.0  2020-01-09 04:20:17.0  \n",
       "4      23.93440     24  24.0  2020-01-09 04:20:17.0  \n",
       "...         ...    ...   ...                    ...  \n",
       "14998  28.49180     30  24.0  2020-11-06 04:21:15.0  \n",
       "14999  28.91800     30  24.0  2020-11-06 04:21:15.0  \n",
       "15000  25.24590     24  24.0  2020-11-06 04:21:15.0  \n",
       "15001  25.24590     24  24.0  2020-11-06 04:21:15.0  \n",
       "15002  27.54100     30  24.0  2020-11-07 04:57:56.0  \n",
       "\n",
       "[15003 rows x 113 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ADNIMERGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5384e4be-6dd6-4040-8408-e13aca7b8bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'CN': 775, 'AD': 409, 'LMCI': 1430})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# какое количество классов в нашем сэмпле ADNI\n",
    "Counter(pd.read_csv('our_subj_adnimerge.csv')['DX_bl'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91b4e337-e76c-4d5d-aef4-750954833534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ADNI1': 2613, 'ADNI2': 1})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pd.read_csv('our_subj_adnimerge.csv')['COLPROT'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b9a93-f90d-4dda-bc9b-a29209abb852",
   "metadata": {},
   "source": [
    "# Делаем dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "45a4fab4-c919-4de1-80b9-abf16f84f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/druzhininapo/nfs/caps/subjects/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e97ce218-1531-4c7e-95a0-314953ad2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(adni_merge, resize=64):\n",
    "    resizer_ = monai.transforms.Resize((resize, resize, resize))\n",
    "    label2num = {\n",
    "        'AD': 1,\n",
    "        'LMCI': 0,\n",
    "    }\n",
    "    dataset = {}\n",
    "    for subj in tqdm(np.unique(adni_merge_1[['PTID']].values)):\n",
    "        subj_path = subj.replace('_', '')\n",
    "        for ses in os.listdir(os.path.join(BASE_PATH, f\"sub-ADNI{subj_path}\")):\n",
    "            subj_samples = adni_merge[adni_merge['PTID'] == subj]\n",
    "            if subj_samples[subj_samples['VISCODE'] == ses.split('-')[1].lower()].shape[0] == 0:\n",
    "                continue\n",
    "            label_text = subj_samples[subj_samples['VISCODE'] == ses.split('-')[1].lower()]['DX_bl'].values[0]\n",
    "            if label_text not in label2num:\n",
    "                continue\n",
    "            \n",
    "            path_to_tensor = os.path.join(BASE_PATH, f\"sub-ADNI{subj_path}\", ses, 'deeplearning_prepare_data/image_based/t1_linear/')\n",
    "            image_tensor = torch.load(os.path.join(path_to_tensor, os.listdir(path_to_tensor)[0]))\n",
    "            \n",
    "            if resize:\n",
    "                image_tensor = resizer_(image_tensor).get_array()\n",
    "\n",
    "            if subj in dataset:\n",
    "                dataset[subj].append((image_tensor, label2num[label_text]))\n",
    "            else:\n",
    "                dataset[subj] = [(image_tensor, label2num[label_text])]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "85ee916e-49b1-46a1-8a39-eae703777677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 771/771 [07:23<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = make_dataset(adni_merge_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98416640-8003-4fab-8406-ec0aa363f0ff",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "be29ccfb-bbad-4d1a-9cc2-492d460005fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = torch.tensor(self.images[index])\n",
    "\n",
    "        return {'tensor': image, 'label': self.labels[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "475ccd6c-44ab-44d5-8a8c-725fc8131953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def get_dataloder(dataset_dict, config_params):\n",
    "\n",
    "    def make_tensors(set_subj):\n",
    "        X = []\n",
    "        y = []\n",
    "        for subj in set_subj:\n",
    "            for tensor, label in dataset_dict[subj]:\n",
    "                X.append(tensor)\n",
    "                y.append(label)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    all_keys_subj = np.sort(list(dataset_dict.keys()))\n",
    "    kfold = KFold(n_splits=config_params['training_params']['count_folds_splits'], random_state=29, shuffle=True)\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(all_keys_subj)):\n",
    "        \n",
    "        if config_params['training_params']['verbose_train']:\n",
    "            print(f\"Number fold: {i+1}\")\n",
    "    \n",
    "        X_train, y_train = make_tensors(all_keys_subj[train_idx])\n",
    "        X_test, y_test = make_tensors(all_keys_subj[test_idx])\n",
    "\n",
    "        mri_dataset_train = MRIDataset(X_train, y_train)\n",
    "        mri_dataset_test = MRIDataset(X_test, y_test)\n",
    "\n",
    "        mri_dataloader_train = torch.utils.data.DataLoader(mri_dataset_train,\n",
    "                                                           batch_size=config_params['training_params']['batch_size'],\n",
    "                                                           shuffle=True)\n",
    "        mri_dataloader_test = torch.utils.data.DataLoader(mri_dataset_test, batch_size=1, shuffle=False)\n",
    "    \n",
    "        yield mri_dataloader_train, mri_dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "64463c81-a0f4-4d5b-9de6-bf0ba7caf3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vit(dataset_dict, config_params, thr=0.5, use_checkpoint=False):\n",
    "    auc_folds = []\n",
    "\n",
    "    if not os.path.exists(config_params['result_path']):\n",
    "        os.mkdir(config_params['result_path'])\n",
    "\n",
    "    file_log = open(os.path.join(config_params['result_path'], 'logs.txt'), 'w')\n",
    "\n",
    "    print(f\"Name of exp: {config_params['name_exp']}\")\n",
    "    file_log.write(f\"Name of exp: {config_params['name_exp']}\\n\")\n",
    "\n",
    "    device = torch.device(config_params['global_params']['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    max_auc_folds = []\n",
    "    num_fold = 0\n",
    "    for train_dataloader, test_dataloader in get_dataloder(dataset_dict,\n",
    "                                                           config_params,):\n",
    "        num_fold += 1\n",
    "        file_log.write(f\"Fold: {num_fold}\\n\")\n",
    "\n",
    "        if config_params['model_params']['model_name'] == 'MiNiT':\n",
    "            model = MINiT(\n",
    "                block_size = config_params['model_params']['block_size'],\n",
    "                image_size = config_params['model_params']['image_size'],\n",
    "                patch_size = config_params['model_params']['patch_size'],\n",
    "                num_classes = config_params['model_params']['num_classes'],\n",
    "                channels = config_params['model_params']['channels'],\n",
    "                dim = config_params['model_params']['dim'],\n",
    "                depth = config_params['model_params']['depth'],\n",
    "                heads = config_params['model_params']['heads'],\n",
    "                mlp_dim = config_params['model_params']['mlp_dim'],\n",
    "            ).train().to(device)\n",
    "        elif config_params['model_params']['model_name'] == 'ViT':\n",
    "            model = OwnViT(\n",
    "                in_channels = config_params['model_params']['in_channels'],\n",
    "                img_size = (config_params['model_params']['img_size'],\n",
    "                            config_params['model_params']['img_size'],\n",
    "                            config_params['model_params']['img_size']),\n",
    "                patch_size = (config_params['model_params']['patch_size'],\n",
    "                              config_params['model_params']['patch_size'],\n",
    "                              config_params['model_params']['patch_size']),\n",
    "                num_layers = config_params['model_params']['num_layers'],\n",
    "                num_heads = config_params['model_params']['num_heads'],\n",
    "                hidden_size = config_params['model_params']['hidden_size'],\n",
    "                pos_embed = config_params['model_params']['pos_embed'],\n",
    "                qkv_bias = config_params['model_params']['qkv_bias'],\n",
    "                classification = config_params['model_params']['classification'],\n",
    "                num_classes = config_params['model_params']['num_classes'],\n",
    "                post_activation = config_params['model_params']['post_activation'],\n",
    "                spatial_dims = config_params['model_params']['spatial_dims'],\n",
    "            ).train().to(device)\n",
    "\n",
    "        if config_params['training_params']['use_checkpoint']:\n",
    "            checkpoint = torch.load(\"MINIT/minit.pt\")\n",
    "            state = checkpoint['model_state_dict']\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config_params['training_params']['lr'])\n",
    "        loss = nn.BCELoss()\n",
    "\n",
    "        auc_folds = []\n",
    "        max_auc = -1.0\n",
    "\n",
    "        for epoch in range(config_params['training_params']['epoch_num']):\n",
    "            print(f\"Train step\")\n",
    "            file_log.write(f\"Train step\\n\")\n",
    "\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if config_params['model_params']['model_name'] == 'MiNiT':\n",
    "                    outputs = model(brain_img)\n",
    "                elif config_params['model_params']['model_name'] == 'ViT':\n",
    "                    outputs, _ = model(brain_img)\n",
    "                loss_calc = loss(torch.squeeze(outputs, 1), labels.float())\n",
    "\n",
    "                loss_calc.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_train_loss += loss_calc.item()\n",
    "                if i % 24 == 0:\n",
    "                    print(f\"Epoch: {epoch+1}, step: {i+1} / {len(train_dataloader)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "                    file_log.write(f\"Epoch: {epoch+1}, step: {i+1} / {len(train_dataloader)}, loss: {epoch_train_loss / (i+1)}\\n\")\n",
    "\n",
    "            print(f\"Test step\")\n",
    "            file_log.write(f\"Test step\\n\")\n",
    "\n",
    "            model.eval()\n",
    "            #labels_pred = []\n",
    "            logits_pred = []\n",
    "            y_test = []\n",
    "            for i, batch in enumerate(test_dataloader):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if config_params['model_params']['model_name'] == 'MiNiT':\n",
    "                        output_prob = torch.sigmoid(model(brain_img)).item()\n",
    "                    elif config_params['model_params']['model_name'] == 'ViT':\n",
    "                        output_prob = model(brain_img)[0].item()\n",
    "                    logits_pred.append(output_prob)\n",
    "                    y_test.append(labels.item())\n",
    "                    #print(output_prob, labels.item())\n",
    "                    #labels_pred.append(1 if output_prob > config_params['training_params']['thr_metirc'] else 0)\n",
    "      \n",
    "            #precision_score_fold = precision_score(y_test, labels_pred)\n",
    "            #recall_score_fold = recall_score(y_test, labels_pred)\n",
    "            auc_fold = roc_auc_score(y_test, logits_pred)\n",
    "\n",
    "            if auc_fold > max_auc:\n",
    "                max_auc = auc_fold\n",
    "                torch.save(model.state_dict(),\n",
    "                           os.path.join(config_params['result_path'],\n",
    "                           f\"best_model_fold_{num_fold}.pth\"))\n",
    "\n",
    "            auc_folds.append(auc_fold)\n",
    "\n",
    "            print(f\"AUC: {auc_fold}\")\n",
    "            file_log.write(f\"AUC: {auc_fold}\\n\")\n",
    "\n",
    "        max_auc_folds.append(max_auc)\n",
    "\n",
    "    file_log.write(f\"Mean AUC: {np.mean(max_auc_folds)}\")\n",
    "    file_log.close()\n",
    "    return auc_folds, max_auc_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab6798-6593-4966-9cfa-e983c14853c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model = ViT(in_channels=1,\n",
    "   img_size=64,\n",
    "   patch_size=8,\n",
    "               classification=True,\n",
    "               num_classes=1,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ca604-1d12-4469-857a-7feabca928c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_config = 'ad_cd_vit_3.yaml'\n",
    "#name_config = 'ad_lmci_minit.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f6b58d5b-1e1a-4dea-aab0-b7ac839d9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_config = 'ad_lmci_minit.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0db853b2-24f6-4939-9185-851e29523164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(os.path.join(\"./exp_configs\", name_config), \"r\") as stream:\n",
    "    try:\n",
    "        config_params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6e34f3c0-9e94-492d-9e00-db5add714eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name_exp': 'AD vs LMCI MiNiT',\n",
       " 'result_path': './results/ad_lmci_minit/',\n",
       " 'image_size': 64,\n",
       " 'global_params': {'device': 'cuda:0'},\n",
       " 'model_params': {'model_name': 'MiNiT',\n",
       "  'block_size': 8,\n",
       "  'image_size': 64,\n",
       "  'patch_size': 8,\n",
       "  'num_classes': 1,\n",
       "  'channels': 1,\n",
       "  'dim': 256,\n",
       "  'depth': 6,\n",
       "  'heads': 4,\n",
       "  'mlp_dim': 309},\n",
       " 'training_params': {'lr': 0.005,\n",
       "  'count_folds_splits': 10,\n",
       "  'use_checkpoint': False,\n",
       "  'verbose_make_dataset': True,\n",
       "  'verbose_train': True,\n",
       "  'thr_metirc': 0.5,\n",
       "  'batch_size': 6,\n",
       "  'epoch_num': 4}}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fc64eb13-17be-4670-b677-03608066b79b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of exp: AD vs LMCI MiNiT\n",
      "Number fold: 1\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.3578466176986694\n",
      "Epoch: 1, step: 25 / 232, loss: 2.6825997638702392\n",
      "Epoch: 1, step: 49 / 232, loss: 2.614070858274187\n",
      "Epoch: 1, step: 73 / 232, loss: 2.3800291427194256\n",
      "Epoch: 1, step: 97 / 232, loss: 2.2295218890475246\n",
      "Epoch: 1, step: 121 / 232, loss: 2.2001498356338374\n",
      "Epoch: 1, step: 145 / 232, loss: 2.088273521127372\n",
      "Epoch: 1, step: 169 / 232, loss: 2.077956741378152\n",
      "Epoch: 1, step: 193 / 232, loss: 2.1526555014397815\n",
      "Epoch: 1, step: 217 / 232, loss: 2.1163320458979102\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5263888888888889\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.0327186584472656\n",
      "Epoch: 2, step: 25 / 232, loss: 2.009307804107666\n",
      "Epoch: 2, step: 49 / 232, loss: 1.8960718086787633\n",
      "Epoch: 2, step: 73 / 232, loss: 1.8858051712382329\n",
      "Epoch: 2, step: 97 / 232, loss: 1.9898126816626676\n",
      "Epoch: 2, step: 121 / 232, loss: 2.0293867097905847\n",
      "Epoch: 2, step: 145 / 232, loss: 1.9842679378287547\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8977047792200505\n",
      "Epoch: 2, step: 193 / 232, loss: 1.9633754657031341\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9607755543174832\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5260942760942761\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 2.782687187194824\n",
      "Epoch: 3, step: 25 / 232, loss: 1.9313577032089233\n",
      "Epoch: 3, step: 49 / 232, loss: 1.9667069230760847\n",
      "Epoch: 3, step: 73 / 232, loss: 2.0826977936372364\n",
      "Epoch: 3, step: 97 / 232, loss: 2.065128060038557\n",
      "Epoch: 3, step: 121 / 232, loss: 1.9840224120488836\n",
      "Epoch: 3, step: 145 / 232, loss: 1.9109029236538657\n",
      "Epoch: 3, step: 169 / 232, loss: 1.8308826405885656\n",
      "Epoch: 3, step: 193 / 232, loss: 1.7885078892420612\n",
      "Epoch: 3, step: 217 / 232, loss: 1.7907359231658246\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6319865319865321\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 2.2407066822052\n",
      "Epoch: 4, step: 25 / 232, loss: 1.8719015854597092\n",
      "Epoch: 4, step: 49 / 232, loss: 1.6237434598864342\n",
      "Epoch: 4, step: 73 / 232, loss: 1.7573372074594236\n",
      "Epoch: 4, step: 97 / 232, loss: 1.630548845246895\n",
      "Epoch: 4, step: 121 / 232, loss: 1.684220245061827\n",
      "Epoch: 4, step: 145 / 232, loss: 1.637322079801354\n",
      "Epoch: 4, step: 169 / 232, loss: 1.6312375528704839\n",
      "Epoch: 4, step: 193 / 232, loss: 1.6818576925892594\n",
      "Epoch: 4, step: 217 / 232, loss: 1.6402529451807248\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7079966329966331\n",
      "Number fold: 2\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.3888145685195923\n",
      "Epoch: 1, step: 25 / 232, loss: 2.1595096683502195\n",
      "Epoch: 1, step: 49 / 232, loss: 2.093582802889298\n",
      "Epoch: 1, step: 73 / 232, loss: 2.0394390609166395\n",
      "Epoch: 1, step: 97 / 232, loss: 2.1495864520367887\n",
      "Epoch: 1, step: 121 / 232, loss: 2.0968118733610988\n",
      "Epoch: 1, step: 145 / 232, loss: 2.0246567027322175\n",
      "Epoch: 1, step: 169 / 232, loss: 2.0630850097131446\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0889182879053867\n",
      "Epoch: 1, step: 217 / 232, loss: 2.052993082025084\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 0.0\n",
      "Epoch: 2, step: 25 / 232, loss: 2.098764533996582\n",
      "Epoch: 2, step: 49 / 232, loss: 1.9539299838396968\n",
      "Epoch: 2, step: 73 / 232, loss: 1.8403961462517306\n",
      "Epoch: 2, step: 97 / 232, loss: 1.7636509903312958\n",
      "Epoch: 2, step: 121 / 232, loss: 1.6888412761786753\n",
      "Epoch: 2, step: 145 / 232, loss: 1.6923681656701555\n",
      "Epoch: 2, step: 169 / 232, loss: 1.7492109753009615\n",
      "Epoch: 2, step: 193 / 232, loss: 1.7856313213199337\n",
      "Epoch: 2, step: 217 / 232, loss: 1.7265709467502612\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7764309764309765\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 1.1810178756713867\n",
      "Epoch: 3, step: 25 / 232, loss: 1.3557023572921754\n",
      "Epoch: 3, step: 49 / 232, loss: 1.6829897895151256\n",
      "Epoch: 3, step: 73 / 232, loss: 1.8853372245618742\n",
      "Epoch: 3, step: 97 / 232, loss: 1.9164005017157681\n",
      "Epoch: 3, step: 121 / 232, loss: 1.913553323011753\n",
      "Epoch: 3, step: 145 / 232, loss: 1.8685212204168582\n",
      "Epoch: 3, step: 169 / 232, loss: 1.8246593936704671\n",
      "Epoch: 3, step: 193 / 232, loss: 1.7732704911245891\n",
      "Epoch: 3, step: 217 / 232, loss: 1.7457346276719174\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 1.7745699882507324\n",
      "Epoch: 4, step: 25 / 232, loss: 1.6365837860107422\n",
      "Epoch: 4, step: 49 / 232, loss: 1.7103334245633106\n",
      "Epoch: 4, step: 73 / 232, loss: 1.6553731462726855\n",
      "Epoch: 4, step: 97 / 232, loss: 1.5078418175353832\n",
      "Epoch: 4, step: 121 / 232, loss: 1.498589782213623\n",
      "Epoch: 4, step: 145 / 232, loss: 1.5220719156851028\n",
      "Epoch: 4, step: 169 / 232, loss: 1.5731327819621421\n",
      "Epoch: 4, step: 193 / 232, loss: 1.560611512859405\n",
      "Epoch: 4, step: 217 / 232, loss: 1.5759742773794634\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Number fold: 3\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 0.0\n",
      "Epoch: 1, step: 25 / 232, loss: 1.8573773527145385\n",
      "Epoch: 1, step: 49 / 232, loss: 1.9797794745892894\n",
      "Epoch: 1, step: 73 / 232, loss: 1.9746387935664556\n",
      "Epoch: 1, step: 97 / 232, loss: 1.9176577003960757\n",
      "Epoch: 1, step: 121 / 232, loss: 1.946343288441335\n",
      "Epoch: 1, step: 145 / 232, loss: 1.9551543128901514\n",
      "Epoch: 1, step: 169 / 232, loss: 1.9728293214323958\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0351642141688053\n",
      "Epoch: 1, step: 217 / 232, loss: 2.1681553018257915\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.4484848484848485\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 1.4567680358886719\n",
      "Epoch: 2, step: 25 / 232, loss: 2.182289357185364\n",
      "Epoch: 2, step: 49 / 232, loss: 2.2484131370271956\n",
      "Epoch: 2, step: 73 / 232, loss: 2.199649939798329\n",
      "Epoch: 2, step: 97 / 232, loss: 2.140807584388969\n",
      "Epoch: 2, step: 121 / 232, loss: 2.224042296902207\n",
      "Epoch: 2, step: 145 / 232, loss: 2.127001303228839\n",
      "Epoch: 2, step: 169 / 232, loss: 2.1428900063037872\n",
      "Epoch: 2, step: 193 / 232, loss: 2.142171577005189\n",
      "Epoch: 2, step: 217 / 232, loss: 2.1799219622864703\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.46675084175084175\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 2.682061195373535\n",
      "Epoch: 3, step: 25 / 232, loss: 2.005209221839905\n",
      "Epoch: 3, step: 49 / 232, loss: 2.243298355413943\n",
      "Epoch: 3, step: 73 / 232, loss: 2.141750100540788\n",
      "Epoch: 3, step: 97 / 232, loss: 2.1717971256098796\n",
      "Epoch: 3, step: 121 / 232, loss: 2.154457488335854\n",
      "Epoch: 3, step: 145 / 232, loss: 2.1130295679487032\n",
      "Epoch: 3, step: 169 / 232, loss: 2.0664494757116194\n",
      "Epoch: 3, step: 193 / 232, loss: 2.0673049904521883\n",
      "Epoch: 3, step: 217 / 232, loss: 2.067515301814277\n",
      "Test step\n",
      "Precision: 0.22310756972111553\n",
      "Recall: 0.9333333333333333\n",
      "AUC: 0.4593434343434344\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 4.103153705596924\n",
      "Epoch: 4, step: 25 / 232, loss: 1.98923846244812\n",
      "Epoch: 4, step: 49 / 232, loss: 1.9196752212485488\n",
      "Epoch: 4, step: 73 / 232, loss: 1.9434076384322283\n",
      "Epoch: 4, step: 97 / 232, loss: 2.0472179257992615\n",
      "Epoch: 4, step: 121 / 232, loss: 2.0187109994494223\n",
      "Epoch: 4, step: 145 / 232, loss: 2.097813836048389\n",
      "Epoch: 4, step: 169 / 232, loss: 2.0866837568537018\n",
      "Epoch: 4, step: 193 / 232, loss: 2.044469560675053\n",
      "Epoch: 4, step: 217 / 232, loss: 2.0465245097875595\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6801346801346801\n",
      "Number fold: 4\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 0.0\n",
      "Epoch: 1, step: 25 / 232, loss: 2.419949016571045\n",
      "Epoch: 1, step: 49 / 232, loss: 2.478117453808687\n",
      "Epoch: 1, step: 73 / 232, loss: 2.441795241342832\n",
      "Epoch: 1, step: 97 / 232, loss: 2.4263837190018487\n",
      "Epoch: 1, step: 121 / 232, loss: 2.23594199921474\n",
      "Epoch: 1, step: 145 / 232, loss: 2.2264438378399816\n",
      "Epoch: 1, step: 169 / 232, loss: 2.138066559500948\n",
      "Epoch: 1, step: 193 / 232, loss: 2.129798482427943\n",
      "Epoch: 1, step: 217 / 232, loss: 2.097778836428295\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5966329966329967\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.747283935546875\n",
      "Epoch: 2, step: 25 / 232, loss: 2.160108897686005\n",
      "Epoch: 2, step: 49 / 232, loss: 1.9769931776182992\n",
      "Epoch: 2, step: 73 / 232, loss: 1.9004664233286086\n",
      "Epoch: 2, step: 97 / 232, loss: 1.8719512592885912\n",
      "Epoch: 2, step: 121 / 232, loss: 1.9114364026006587\n",
      "Epoch: 2, step: 145 / 232, loss: 1.8409517843147805\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8742305364834486\n",
      "Epoch: 2, step: 193 / 232, loss: 1.941993136788897\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9411578010853534\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.7118686868686869\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 0.5639861822128296\n",
      "Epoch: 3, step: 25 / 232, loss: 1.735484504699707\n",
      "Epoch: 3, step: 49 / 232, loss: 1.5213529832509098\n",
      "Epoch: 3, step: 73 / 232, loss: 1.441824527738029\n",
      "Epoch: 3, step: 97 / 232, loss: 1.505860908513831\n",
      "Epoch: 3, step: 121 / 232, loss: 1.661072805215997\n",
      "Epoch: 3, step: 145 / 232, loss: 1.7292071213496143\n",
      "Epoch: 3, step: 169 / 232, loss: 1.6521542198823753\n",
      "Epoch: 3, step: 193 / 232, loss: 1.6855689293362317\n",
      "Epoch: 3, step: 217 / 232, loss: 1.7812125076803225\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 1.341102123260498\n",
      "Epoch: 4, step: 25 / 232, loss: 1.512661613225937\n",
      "Epoch: 4, step: 49 / 232, loss: 1.3986862456920195\n",
      "Epoch: 4, step: 73 / 232, loss: 1.5828191537971366\n",
      "Epoch: 4, step: 97 / 232, loss: 1.6074715080027728\n",
      "Epoch: 4, step: 121 / 232, loss: 1.579930132331927\n",
      "Epoch: 4, step: 145 / 232, loss: 1.5685368637586463\n",
      "Epoch: 4, step: 169 / 232, loss: 1.5549380396597483\n",
      "Epoch: 4, step: 193 / 232, loss: 1.6269434753786096\n",
      "Epoch: 4, step: 217 / 232, loss: 1.6601503282648078\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Number fold: 5\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 2.7531144618988037\n",
      "Epoch: 1, step: 25 / 232, loss: 2.4737194395065307\n",
      "Epoch: 1, step: 49 / 232, loss: 2.241155967420461\n",
      "Epoch: 1, step: 73 / 232, loss: 2.2026520248961776\n",
      "Epoch: 1, step: 97 / 232, loss: 2.1586996538122905\n",
      "Epoch: 1, step: 121 / 232, loss: 2.2216079146408836\n",
      "Epoch: 1, step: 145 / 232, loss: 2.094010487096063\n",
      "Epoch: 1, step: 169 / 232, loss: 2.124818495039404\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0621659582760667\n",
      "Epoch: 1, step: 217 / 232, loss: 2.0781448063213155\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5760942760942761\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 0.0\n",
      "Epoch: 2, step: 25 / 232, loss: 1.7835153245925903\n",
      "Epoch: 2, step: 49 / 232, loss: 1.9191069529981029\n",
      "Epoch: 2, step: 73 / 232, loss: 2.0056262269412\n",
      "Epoch: 2, step: 97 / 232, loss: 1.9823533941790001\n",
      "Epoch: 2, step: 121 / 232, loss: 2.0147652542295535\n",
      "Epoch: 2, step: 145 / 232, loss: 1.9963149535244908\n",
      "Epoch: 2, step: 169 / 232, loss: 1.9898307672619113\n",
      "Epoch: 2, step: 193 / 232, loss: 1.9703335741949823\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9535359315883178\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5993265993265993\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 0.0\n",
      "Epoch: 3, step: 25 / 232, loss: 1.7941575098037719\n",
      "Epoch: 3, step: 49 / 232, loss: 1.8324468398124587\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9017436949867907\n",
      "Epoch: 3, step: 97 / 232, loss: 1.8699616191083008\n",
      "Epoch: 3, step: 121 / 232, loss: 1.876660528538887\n",
      "Epoch: 3, step: 145 / 232, loss: 1.8506205848835666\n",
      "Epoch: 3, step: 169 / 232, loss: 1.8566141599601895\n",
      "Epoch: 3, step: 193 / 232, loss: 1.8453137705710576\n",
      "Epoch: 3, step: 217 / 232, loss: 1.8401171604368818\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.6515993265993266\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 2.296588897705078\n",
      "Epoch: 4, step: 25 / 232, loss: 1.569852209687233\n",
      "Epoch: 4, step: 49 / 232, loss: 1.6660437599128606\n",
      "Epoch: 4, step: 73 / 232, loss: 1.5657405792033836\n",
      "Epoch: 4, step: 97 / 232, loss: 1.6507717705879015\n",
      "Epoch: 4, step: 121 / 232, loss: 1.6105006012049587\n",
      "Epoch: 4, step: 145 / 232, loss: 1.6081251623301671\n",
      "Epoch: 4, step: 169 / 232, loss: 1.5978529181926562\n",
      "Epoch: 4, step: 193 / 232, loss: 1.655685297893891\n",
      "Epoch: 4, step: 217 / 232, loss: 1.6367169760236269\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.6548821548821548\n",
      "Number fold: 6\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 0.0\n",
      "Epoch: 1, step: 25 / 232, loss: 1.8635019207000731\n",
      "Epoch: 1, step: 49 / 232, loss: 2.0238175635435143\n",
      "Epoch: 1, step: 73 / 232, loss: 2.120640411768874\n",
      "Epoch: 1, step: 97 / 232, loss: 2.2475292989888143\n",
      "Epoch: 1, step: 121 / 232, loss: 2.2153563408319616\n",
      "Epoch: 1, step: 145 / 232, loss: 2.2461875444856183\n",
      "Epoch: 1, step: 169 / 232, loss: 2.2242710123048024\n",
      "Epoch: 1, step: 193 / 232, loss: 2.1647910588454704\n",
      "Epoch: 1, step: 217 / 232, loss: 2.106850058115023\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.057953357696533\n",
      "Epoch: 2, step: 25 / 232, loss: 1.6785358309745788\n",
      "Epoch: 2, step: 49 / 232, loss: 1.6597781582754485\n",
      "Epoch: 2, step: 73 / 232, loss: 1.7521451589179367\n",
      "Epoch: 2, step: 97 / 232, loss: 1.763237510759806\n",
      "Epoch: 2, step: 121 / 232, loss: 1.726037958436761\n",
      "Epoch: 2, step: 145 / 232, loss: 1.8857542436698387\n",
      "Epoch: 2, step: 169 / 232, loss: 1.9362523608659146\n",
      "Epoch: 2, step: 193 / 232, loss: 1.963831403249286\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9154048437072384\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 2.5938425064086914\n",
      "Epoch: 3, step: 25 / 232, loss: 2.022306354045868\n",
      "Epoch: 3, step: 49 / 232, loss: 1.9338770703393586\n",
      "Epoch: 3, step: 73 / 232, loss: 1.718302383610647\n",
      "Epoch: 3, step: 97 / 232, loss: 1.6068140795243155\n",
      "Epoch: 3, step: 121 / 232, loss: 1.6508564615298893\n",
      "Epoch: 3, step: 145 / 232, loss: 1.7469418756920716\n",
      "Epoch: 3, step: 169 / 232, loss: 1.7609114518179696\n",
      "Epoch: 3, step: 193 / 232, loss: 1.923168493521646\n",
      "Epoch: 3, step: 217 / 232, loss: 1.8961021442841823\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5616161616161616\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 0.0\n",
      "Epoch: 4, step: 25 / 232, loss: 2.242004566192627\n",
      "Epoch: 4, step: 49 / 232, loss: 2.0589768558132406\n",
      "Epoch: 4, step: 73 / 232, loss: 1.8195455858152207\n",
      "Epoch: 4, step: 97 / 232, loss: 1.818615436553955\n",
      "Epoch: 4, step: 121 / 232, loss: 1.7478871153405875\n",
      "Epoch: 4, step: 145 / 232, loss: 1.772054354897861\n",
      "Epoch: 4, step: 169 / 232, loss: 1.7350277302004176\n",
      "Epoch: 4, step: 193 / 232, loss: 1.77555253383718\n",
      "Epoch: 4, step: 217 / 232, loss: 1.7913467314454816\n",
      "Test step\n",
      "Precision: 0.625\n",
      "Recall: 0.08333333333333333\n",
      "AUC: 0.6318181818181816\n",
      "Number fold: 7\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.39594304561615\n",
      "Epoch: 1, step: 25 / 232, loss: 2.3747167015075683\n",
      "Epoch: 1, step: 49 / 232, loss: 2.3758950549729017\n",
      "Epoch: 1, step: 73 / 232, loss: 2.1460457321715682\n",
      "Epoch: 1, step: 97 / 232, loss: 2.157019697513777\n",
      "Epoch: 1, step: 121 / 232, loss: 2.2161276202556515\n",
      "Epoch: 1, step: 145 / 232, loss: 2.20484546464065\n",
      "Epoch: 1, step: 169 / 232, loss: 2.083862890505932\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0587047292160863\n",
      "Epoch: 1, step: 217 / 232, loss: 2.054889532552886\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7664141414141413\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.781757354736328\n",
      "Epoch: 2, step: 25 / 232, loss: 2.85910626411438\n",
      "Epoch: 2, step: 49 / 232, loss: 2.4436018856204287\n",
      "Epoch: 2, step: 73 / 232, loss: 2.3778408047271102\n",
      "Epoch: 2, step: 97 / 232, loss: 2.2640933744686165\n",
      "Epoch: 2, step: 121 / 232, loss: 2.240818966518749\n",
      "Epoch: 2, step: 145 / 232, loss: 2.2104716342071007\n",
      "Epoch: 2, step: 169 / 232, loss: 2.1411801516657043\n",
      "Epoch: 2, step: 193 / 232, loss: 2.055691071124892\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9912152627852107\n",
      "Test step\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.03333333333333333\n",
      "AUC: 0.7784511784511785\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 4.036620140075684\n",
      "Epoch: 3, step: 25 / 232, loss: 1.9904972076416017\n",
      "Epoch: 3, step: 49 / 232, loss: 1.8598138312904202\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9110685782889798\n",
      "Epoch: 3, step: 97 / 232, loss: 1.75399086678151\n",
      "Epoch: 3, step: 121 / 232, loss: 1.6864744945744838\n",
      "Epoch: 3, step: 145 / 232, loss: 1.640312841431848\n",
      "Epoch: 3, step: 169 / 232, loss: 1.748003759118315\n",
      "Epoch: 3, step: 193 / 232, loss: 1.6928441150528935\n",
      "Epoch: 3, step: 217 / 232, loss: 1.6746720391226941\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7724747474747475\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 0.0\n",
      "Epoch: 4, step: 25 / 232, loss: 1.3823825538158416\n",
      "Epoch: 4, step: 49 / 232, loss: 1.49912413224882\n",
      "Epoch: 4, step: 73 / 232, loss: 1.3697787008873403\n",
      "Epoch: 4, step: 97 / 232, loss: 1.423785741488958\n",
      "Epoch: 4, step: 121 / 232, loss: 1.6208926482079935\n",
      "Epoch: 4, step: 145 / 232, loss: 1.6808821093162587\n",
      "Epoch: 4, step: 169 / 232, loss: 1.6402667978414769\n",
      "Epoch: 4, step: 193 / 232, loss: 1.749392500716633\n",
      "Epoch: 4, step: 217 / 232, loss: 1.7195528170720498\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.723526936026936\n",
      "Number fold: 8\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.3678829669952393\n",
      "Epoch: 1, step: 25 / 232, loss: 1.9638892269134522\n",
      "Epoch: 1, step: 49 / 232, loss: 1.950443956316734\n",
      "Epoch: 1, step: 73 / 232, loss: 2.037104750741018\n",
      "Epoch: 1, step: 97 / 232, loss: 2.0901171684879616\n",
      "Epoch: 1, step: 121 / 232, loss: 2.0803780045883715\n",
      "Epoch: 1, step: 145 / 232, loss: 2.0562877254239442\n",
      "Epoch: 1, step: 169 / 232, loss: 2.054216065526714\n",
      "Epoch: 1, step: 193 / 232, loss: 2.1217588663410027\n",
      "Epoch: 1, step: 217 / 232, loss: 2.096497175468278\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.6481060606060606\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 0.9951459169387817\n",
      "Epoch: 2, step: 25 / 232, loss: 1.7291499888896942\n",
      "Epoch: 2, step: 49 / 232, loss: 1.8503503598728959\n",
      "Epoch: 2, step: 73 / 232, loss: 1.774364897649582\n",
      "Epoch: 2, step: 97 / 232, loss: 1.7855232536178274\n",
      "Epoch: 2, step: 121 / 232, loss: 1.8135042818617229\n",
      "Epoch: 2, step: 145 / 232, loss: 1.7897286861107267\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8666457676675898\n",
      "Epoch: 2, step: 193 / 232, loss: 1.9154056804785458\n",
      "Epoch: 2, step: 217 / 232, loss: 1.926142306371768\n",
      "Test step\n",
      "Precision: 0.47619047619047616\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.6914983164983165\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 0.8617957234382629\n",
      "Epoch: 3, step: 25 / 232, loss: 2.141496422290802\n",
      "Epoch: 3, step: 49 / 232, loss: 1.8740674932392276\n",
      "Epoch: 3, step: 73 / 232, loss: 1.7917551263554456\n",
      "Epoch: 3, step: 97 / 232, loss: 1.8262167685309942\n",
      "Epoch: 3, step: 121 / 232, loss: 1.845774835437413\n",
      "Epoch: 3, step: 145 / 232, loss: 1.8248413335788867\n",
      "Epoch: 3, step: 169 / 232, loss: 1.82548624657359\n",
      "Epoch: 3, step: 193 / 232, loss: 1.8578949171586512\n",
      "Epoch: 3, step: 217 / 232, loss: 1.8201419458175208\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.6819444444444445\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 1.8210253715515137\n",
      "Epoch: 4, step: 25 / 232, loss: 1.6818003475666046\n",
      "Epoch: 4, step: 49 / 232, loss: 1.6806298780198\n",
      "Epoch: 4, step: 73 / 232, loss: 1.7653471415173518\n",
      "Epoch: 4, step: 97 / 232, loss: 1.7230000290059553\n",
      "Epoch: 4, step: 121 / 232, loss: 1.823095125600326\n",
      "Epoch: 4, step: 145 / 232, loss: 1.795092209865307\n",
      "Epoch: 4, step: 169 / 232, loss: 1.8100780302427224\n",
      "Epoch: 4, step: 193 / 232, loss: 1.8076471588308947\n",
      "Epoch: 4, step: 217 / 232, loss: 1.7847937184132738\n",
      "Test step\n",
      "Precision: 1.0\n",
      "Recall: 0.016666666666666666\n",
      "AUC: 0.6601010101010101\n",
      "Number fold: 9\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.3743197917938232\n",
      "Epoch: 1, step: 25 / 232, loss: 1.7392664575576782\n",
      "Epoch: 1, step: 49 / 232, loss: 2.198973898984948\n",
      "Epoch: 1, step: 73 / 232, loss: 2.0198852787279105\n",
      "Epoch: 1, step: 97 / 232, loss: 1.9747062505213255\n",
      "Epoch: 1, step: 121 / 232, loss: 2.0287291177294473\n",
      "Epoch: 1, step: 145 / 232, loss: 1.9580814189951996\n",
      "Epoch: 1, step: 169 / 232, loss: 1.983272554341858\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0087873479399656\n",
      "Epoch: 1, step: 217 / 232, loss: 1.9890935594722423\n",
      "Test step\n",
      "Precision: 0.6470588235294118\n",
      "Recall: 0.18333333333333332\n",
      "AUC: 0.6436868686868686\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 4.414436340332031\n",
      "Epoch: 2, step: 25 / 232, loss: 1.6187995815277099\n",
      "Epoch: 2, step: 49 / 232, loss: 1.7115973240258742\n",
      "Epoch: 2, step: 73 / 232, loss: 1.775720427297566\n",
      "Epoch: 2, step: 97 / 232, loss: 1.8266872278193838\n",
      "Epoch: 2, step: 121 / 232, loss: 1.7472279127225403\n",
      "Epoch: 2, step: 145 / 232, loss: 1.7209940699667765\n",
      "Epoch: 2, step: 169 / 232, loss: 1.683242762582542\n",
      "Epoch: 2, step: 193 / 232, loss: 1.7441471707017928\n",
      "Epoch: 2, step: 217 / 232, loss: 1.7406219179111142\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.7577861952861954\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 1.5038385391235352\n",
      "Epoch: 3, step: 25 / 232, loss: 1.6607644167542457\n",
      "Epoch: 3, step: 49 / 232, loss: 1.6088326275348663\n",
      "Epoch: 3, step: 73 / 232, loss: 1.5795287861909768\n",
      "Epoch: 3, step: 97 / 232, loss: 1.6721486329801918\n",
      "Epoch: 3, step: 121 / 232, loss: 1.547663490972982\n",
      "Epoch: 3, step: 145 / 232, loss: 1.4664431773639959\n",
      "Epoch: 3, step: 169 / 232, loss: 1.6003366077660457\n",
      "Epoch: 3, step: 193 / 232, loss: 1.5912034545730742\n",
      "Epoch: 3, step: 217 / 232, loss: 1.5716465929789203\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.7075757575757575\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 1.609731912612915\n",
      "Epoch: 4, step: 25 / 232, loss: 1.5641176122426987\n",
      "Epoch: 4, step: 49 / 232, loss: 1.6763751522010686\n",
      "Epoch: 4, step: 73 / 232, loss: 1.5973604795050949\n",
      "Epoch: 4, step: 97 / 232, loss: 1.4952738034663742\n",
      "Epoch: 4, step: 121 / 232, loss: 1.488934678387297\n",
      "Epoch: 4, step: 145 / 232, loss: 1.5159348218862352\n",
      "Epoch: 4, step: 169 / 232, loss: 1.5158148930138031\n",
      "Epoch: 4, step: 193 / 232, loss: 1.5698998576811867\n",
      "Epoch: 4, step: 217 / 232, loss: 1.597705358201595\n",
      "Test step\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7159090909090909\n",
      "Number fold: 10\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 2.7747278213500977\n",
      "Epoch: 1, step: 25 / 232, loss: 2.058792712688446\n",
      "Epoch: 1, step: 49 / 232, loss: 1.9654941960256926\n",
      "Epoch: 1, step: 73 / 232, loss: 2.0250442787392497\n",
      "Epoch: 1, step: 97 / 232, loss: 2.049558615561613\n",
      "Epoch: 1, step: 121 / 232, loss: 2.0792837807954836\n",
      "Epoch: 1, step: 145 / 232, loss: 2.086142833068453\n",
      "Epoch: 1, step: 169 / 232, loss: 2.0600447270291795\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0983625023476202\n",
      "Epoch: 1, step: 217 / 232, loss: 2.1402650700736157\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5932659932659933\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.6983416080474854\n",
      "Epoch: 2, step: 25 / 232, loss: 1.8586100935935974\n",
      "Epoch: 2, step: 49 / 232, loss: 2.084366573362934\n",
      "Epoch: 2, step: 73 / 232, loss: 2.12064584885558\n",
      "Epoch: 2, step: 97 / 232, loss: 2.096965083756398\n",
      "Epoch: 2, step: 121 / 232, loss: 2.0581255693080998\n",
      "Epoch: 2, step: 145 / 232, loss: 2.0801440522588535\n",
      "Epoch: 2, step: 169 / 232, loss: 2.0052675336775696\n",
      "Epoch: 2, step: 193 / 232, loss: 2.0088416483118126\n",
      "Epoch: 2, step: 217 / 232, loss: 2.103628037437316\n",
      "Test step\n",
      "Precision: 0.23036649214659685\n",
      "Recall: 0.7333333333333333\n",
      "AUC: 0.5430976430976431\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 0.0\n",
      "Epoch: 3, step: 25 / 232, loss: 2.0010668325424192\n",
      "Epoch: 3, step: 49 / 232, loss: 1.9226484250049203\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9477068169476235\n",
      "Epoch: 3, step: 97 / 232, loss: 1.9850764569547987\n",
      "Epoch: 3, step: 121 / 232, loss: 2.014196505231306\n",
      "Epoch: 3, step: 145 / 232, loss: 2.020159395398765\n",
      "Epoch: 3, step: 169 / 232, loss: 2.047976933992826\n",
      "Epoch: 3, step: 193 / 232, loss: 2.0516925352225033\n",
      "Epoch: 3, step: 217 / 232, loss: 2.0130124314589435\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5844276094276094\n",
      "Train step\n",
      "Epoch: 4, step: 1 / 232, loss: 3.7439463138580322\n",
      "Epoch: 4, step: 25 / 232, loss: 2.362349452972412\n",
      "Epoch: 4, step: 49 / 232, loss: 2.0911717937917125\n",
      "Epoch: 4, step: 73 / 232, loss: 2.077650920168994\n",
      "Epoch: 4, step: 97 / 232, loss: 2.100173246307471\n",
      "Epoch: 4, step: 121 / 232, loss: 2.138475878425866\n",
      "Epoch: 4, step: 145 / 232, loss: 2.160326509023535\n",
      "Epoch: 4, step: 169 / 232, loss: 2.1025703695751505\n",
      "Epoch: 4, step: 193 / 232, loss: 2.050212743214375\n",
      "Epoch: 4, step: 217 / 232, loss: 2.036305677918245\n",
      "Test step\n",
      "Precision: 1.0\n",
      "Recall: 0.06666666666666667\n",
      "AUC: 0.7673400673400673\n"
     ]
    }
   ],
   "source": [
    "auc_folds, max_auc_folds = train_vit(dataset_dict, config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fa937652-18c0-4da4-b26d-9fecf30bd49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715820707070707"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(max_auc_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2391f7-a3bc-4b9d-842b-d7847f5ace7f",
   "metadata": {},
   "source": [
    "# AutoEnc ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a430dde-d11b-4d85-a70d-7138c341883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Union\n",
    "\n",
    "from monai.networks.nets import ViT, ViTAutoEnc\n",
    "from monai.networks.layers import Conv\n",
    "from monai.utils import ensure_tuple_rep\n",
    "\n",
    "\n",
    "class MVitAutoEnc(nn.Module):\n",
    "    def __init__(self, vit,\n",
    "                in_channels: int,\n",
    "                img_size: Union[Sequence[int], int],\n",
    "                patch_size: Union[Sequence[int], int],\n",
    "                out_channels: int = 1,\n",
    "                deconv_chns: int = 16,\n",
    "                hidden_size: int = 768,\n",
    "                mlp_dim: int = 3072,\n",
    "                num_layers: int = 12,\n",
    "                num_heads: int = 12,\n",
    "                pos_embed: str = \"conv\",\n",
    "                dropout_rate: float = 0.0,\n",
    "                spatial_dims: int = 3,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vit = vit\n",
    "\n",
    "        self.patch_size = ensure_tuple_rep(patch_size, spatial_dims)\n",
    "        self.spatial_dims = spatial_dims\n",
    "        \n",
    "        new_patch_size = [4] * self.spatial_dims\n",
    "        conv_trans = Conv[Conv.CONVTRANS, self.spatial_dims]\n",
    "        # self.conv3d_transpose* is to be compatible with existing 3d model weights.\n",
    "        self.conv3d_transpose = conv_trans(hidden_size,\n",
    "                                           deconv_chns,\n",
    "                                           kernel_size=new_patch_size,\n",
    "                                           stride=new_patch_size)\n",
    "        self.conv3d_transpose_1 = conv_trans(\n",
    "            in_channels=deconv_chns, out_channels=out_channels, kernel_size=new_patch_size, stride=new_patch_size\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        spatial_size = x.shape[2:]\n",
    "        _, hidden_states = self.vit(x)\n",
    "\n",
    "        x = self.vit.norm(hidden_states[-1])\n",
    "        \n",
    "        x = x.transpose(1, 2)\n",
    "        d = [s // p for s, p in zip(spatial_size, self.patch_size)]\n",
    "        x = torch.reshape(x, [x.shape[0], x.shape[1], *d])\n",
    "        x = self.conv3d_transpose(x)\n",
    "        x = self.conv3d_transpose_1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MVitCls(nn.Module):\n",
    "    def __init__(self, vit,\n",
    "                 hidden_size: int = 768,\n",
    "                 num_classes: int = 2,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vit = vit\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, hidden_size))\n",
    "        self.classification_head = nn.Sequential(nn.Linear(hidden_size, num_classes), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.vit(x)\n",
    "        x = self.classification_head(x[:, 0])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152950a4-f741-4367-98c9-933ba64aff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import ViT\n",
    "\n",
    "vit_model = ViT(in_channels=1,\n",
    "                img_size=(64, 64, 64),\n",
    "                patch_size=(16, 16, 16),\n",
    "                num_layers=4,\n",
    "                pos_embed='conv',\n",
    "                qkv_bias=False,\n",
    "                classification=False,\n",
    "                spatial_dims=3,)\n",
    "\n",
    "\n",
    "mvit = MVitAutoEnc(vit=vit_model,\n",
    "            in_channels=1,\n",
    "            img_size=(64, 64, 64),\n",
    "            patch_size=(16, 16, 16),\n",
    "            spatial_dims=3,)\n",
    "\n",
    "\n",
    "mvit_cls = MVitCls(vit=mvit.vit,\n",
    "                   hidden_size=768,\n",
    "                   num_classes=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa312c-970d-48f4-be3a-8ea9986d0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def get_dataloder(dataset_dict, batch_train_size=4, n_splits=5, verbose=True):\n",
    "\n",
    "    def make_tensors(set_subj):\n",
    "        X = []\n",
    "        y = []\n",
    "        for subj in set_subj:\n",
    "            for tensor, label in dataset_dict[subj]:\n",
    "                X.append(tensor)\n",
    "                y.append(label)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    all_keys_subj = np.sort(list(dataset_dict.keys()))\n",
    "    kfold = KFold(n_splits=n_splits, random_state=29, shuffle=True)\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(all_keys_subj)):\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Number fold: {i+1}\")\n",
    "    \n",
    "        X_train, y_train = make_tensors(all_keys_subj[train_idx])\n",
    "        X_test, y_test = make_tensors(all_keys_subj[test_idx])\n",
    "\n",
    "        mri_dataset_train = MRIDataset(X_train, y_train)\n",
    "        mri_dataset_test = MRIDataset(X_test, y_test)\n",
    "\n",
    "        mri_dataloader_train = torch.utils.data.DataLoader(mri_dataset_train, batch_size=batch_train_size, shuffle=True)\n",
    "        mri_dataloader_test = torch.utils.data.DataLoader(mri_dataset_test, batch_size=1, shuffle=False)\n",
    "    \n",
    "        yield mri_dataloader_train, mri_dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9f29f-ef1f-4b3d-9c31-d63fc1fbeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea3a01-df0a-43fb-8d27-2538d8dba00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auto_enc_vit(dataset_dict, config_params, thr=0.5, use_checkpoint=False):\n",
    "    auc_folds = []\n",
    "\n",
    "    if not os.path.exists(config_params['result_path']):\n",
    "        os.mkdir(config_params['result_path'])\n",
    "\n",
    "    file_log = open(os.path.join(config_params['result_path'], 'logs.txt'), 'w')\n",
    "\n",
    "    print(f\"Name of exp: {config_params['name_exp']}\")\n",
    "    file_log.write(f\"Name of exp: {config_params['name_exp']}\\n\")\n",
    "\n",
    "    device = torch.device(config_params['global_params']['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    max_auc_folds = []\n",
    "    num_fold = 0\n",
    "    for train_dataloader, test_dataloader in get_dataloder(dataset_dict,\n",
    "                                                           config_params,):\n",
    "        num_fold += 1\n",
    "        file_log.write(f\"Fold: {num_fold}\\n\")\n",
    "\n",
    "        if config_params['model_params']['model_name'] == 'ViT':\n",
    "            model = OwnViT(\n",
    "                in_channels = config_params['model_params']['in_channels'],\n",
    "                img_size = (config_params['model_params']['img_size'],\n",
    "                            config_params['model_params']['img_size'],\n",
    "                            config_params['model_params']['img_size']),\n",
    "                patch_size = (config_params['model_params']['patch_size'],\n",
    "                              config_params['model_params']['patch_size'],\n",
    "                              config_params['model_params']['patch_size']),\n",
    "                num_layers = config_params['model_params']['num_layers'],\n",
    "                num_heads = config_params['model_params']['num_heads'],\n",
    "                hidden_size = config_params['model_params']['hidden_size'],\n",
    "                pos_embed = config_params['model_params']['pos_embed'],\n",
    "                qkv_bias = config_params['model_params']['qkv_bias'],\n",
    "                classification = config_params['model_params']['classification'],\n",
    "                num_classes = config_params['model_params']['num_classes'],\n",
    "                post_activation = config_params['model_params']['post_activation'],\n",
    "                spatial_dims = config_params['model_params']['spatial_dims'],\n",
    "            ).train().to(device)\n",
    "\n",
    "        if config_params['training_params']['use_checkpoint']:\n",
    "            checkpoint = torch.load(\"MINIT/minit.pt\")\n",
    "            state = checkpoint['model_state_dict']\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config_params['training_params']['lr'])\n",
    "        loss = nn.BCELoss()\n",
    "\n",
    "        auc_folds = []\n",
    "        max_auc = -1.0\n",
    "\n",
    "        for epoch in range(config_params['training_params']['epoch_num']):\n",
    "            print(f\"Train step\")\n",
    "            file_log.write(f\"Train step\\n\")\n",
    "\n",
    "            model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if config_params['model_params']['model_name'] == 'MiNiT':\n",
    "                    outputs = model(brain_img)\n",
    "                elif config_params['model_params']['model_name'] == 'ViT':\n",
    "                    outputs, _ = model(brain_img)\n",
    "                loss_calc = loss(torch.squeeze(outputs, 1), labels.float())\n",
    "\n",
    "                loss_calc.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_train_loss += loss_calc.item()\n",
    "                if i % 24 == 0:\n",
    "                    print(f\"Epoch: {epoch+1}, step: {i+1} / {len(train_dataloader)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "                    file_log.write(f\"Epoch: {epoch+1}, step: {i+1} / {len(train_dataloader)}, loss: {epoch_train_loss / (i+1)}\\n\")\n",
    "\n",
    "            print(f\"Test step\")\n",
    "            file_log.write(f\"Test step\\n\")\n",
    "\n",
    "            model.eval()\n",
    "            #labels_pred = []\n",
    "            logits_pred = []\n",
    "            y_test = []\n",
    "            for i, batch in enumerate(test_dataloader):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if config_params['model_params']['model_name'] == 'MiNiT':\n",
    "                        output_prob = torch.sigmoid(model(brain_img)).item()\n",
    "                    elif config_params['model_params']['model_name'] == 'ViT':\n",
    "                        output_prob = model(brain_img)[0].item()\n",
    "                    logits_pred.append(output_prob)\n",
    "                    y_test.append(labels.item())\n",
    "\n",
    "            auc_fold = roc_auc_score(y_test, logits_pred)\n",
    "\n",
    "            if auc_fold > max_auc:\n",
    "                max_auc = auc_fold\n",
    "                torch.save(model.state_dict(),\n",
    "                           os.path.join(config_params['result_path'],\n",
    "                           f\"best_model_fold_{num_fold}.pth\"))\n",
    "\n",
    "            auc_folds.append(auc_fold)\n",
    "\n",
    "            print(f\"AUC: {auc_fold}\")\n",
    "            file_log.write(f\"AUC: {auc_fold}\\n\")\n",
    "\n",
    "        max_auc_folds.append(max_auc)\n",
    "\n",
    "    file_log.write(f\"Mean AUC: {np.mean(max_auc_folds)}\")\n",
    "    file_log.close()\n",
    "    return auc_folds, max_auc_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09632d6f-59a5-4663-aefe-7c28a5665e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52532651-5c65-4b59-b85a-ebc3615595af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03a99c3-61d0-41f3-a9cb-acf66282274b",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3ae17632-cb29-4096-94c8-f77d6c022df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 0.0\n",
      "Epoch: 0, step: 9 / 281, loss: 2.394197834862603\n",
      "Epoch: 0, step: 17 / 281, loss: 2.000979598830728\n",
      "Epoch: 0, step: 25 / 281, loss: 2.072249717712402\n",
      "Epoch: 0, step: 33 / 281, loss: 1.838512633786057\n",
      "Epoch: 0, step: 41 / 281, loss: 1.8390611381065556\n",
      "Epoch: 0, step: 49 / 281, loss: 1.676484385315253\n",
      "Epoch: 0, step: 57 / 281, loss: 1.7525349311661302\n",
      "Epoch: 0, step: 65 / 281, loss: 1.7216973625696623\n",
      "Epoch: 0, step: 73 / 281, loss: 1.7372005336905179\n",
      "Epoch: 0, step: 81 / 281, loss: 1.7519290660634452\n",
      "Epoch: 0, step: 89 / 281, loss: 1.7796537909614907\n",
      "Epoch: 0, step: 97 / 281, loss: 1.7823393240417402\n",
      "Epoch: 0, step: 105 / 281, loss: 1.7946016629536947\n",
      "Epoch: 0, step: 113 / 281, loss: 1.804586623622253\n",
      "Epoch: 0, step: 121 / 281, loss: 1.7872062537295759\n",
      "Epoch: 0, step: 129 / 281, loss: 1.7722801626190658\n",
      "Epoch: 0, step: 137 / 281, loss: 1.7688390703967019\n",
      "Epoch: 0, step: 145 / 281, loss: 1.7726228578337309\n",
      "Epoch: 0, step: 153 / 281, loss: 1.7720017296816009\n",
      "Epoch: 0, step: 161 / 281, loss: 1.729567095914983\n",
      "Epoch: 0, step: 169 / 281, loss: 1.813664585704634\n",
      "Epoch: 0, step: 177 / 281, loss: 1.8022387005851768\n",
      "Epoch: 0, step: 185 / 281, loss: 1.7886903986737535\n",
      "Epoch: 0, step: 193 / 281, loss: 1.8301973359881287\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8650463675681632\n",
      "Epoch: 0, step: 209 / 281, loss: 1.8531410008241116\n",
      "Epoch: 0, step: 217 / 281, loss: 1.8192859809794184\n",
      "Epoch: 0, step: 225 / 281, loss: 1.8421772250864241\n",
      "Epoch: 0, step: 233 / 281, loss: 1.8374194775272337\n",
      "Epoch: 0, step: 241 / 281, loss: 1.8478320123496392\n",
      "Epoch: 0, step: 249 / 281, loss: 1.8586241671119828\n",
      "Epoch: 0, step: 257 / 281, loss: 1.851642537789586\n",
      "Epoch: 0, step: 265 / 281, loss: 1.8670091004866474\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8598554519724932\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8730702918831563\n",
      "0.3\n",
      "1.0\n",
      "Epoch: 1, step: 1 / 281, loss: 1.2080230712890625\n",
      "Epoch: 1, step: 9 / 281, loss: 1.4226460456848145\n",
      "Epoch: 1, step: 17 / 281, loss: 1.7462085380273706\n",
      "Epoch: 1, step: 25 / 281, loss: 1.6985968708992005\n",
      "Epoch: 1, step: 33 / 281, loss: 1.6554306131420713\n",
      "Epoch: 1, step: 41 / 281, loss: 1.735095137866532\n",
      "Epoch: 1, step: 49 / 281, loss: 1.7120519879521157\n",
      "Epoch: 1, step: 57 / 281, loss: 1.7641995070796264\n",
      "Epoch: 1, step: 65 / 281, loss: 1.718093097439179\n",
      "Epoch: 1, step: 73 / 281, loss: 1.7823770632074303\n",
      "Epoch: 1, step: 81 / 281, loss: 1.7717989983014117\n",
      "Epoch: 1, step: 89 / 281, loss: 1.7963215680269713\n",
      "Epoch: 1, step: 97 / 281, loss: 1.7352446033475326\n",
      "Epoch: 1, step: 105 / 281, loss: 1.6720560750791005\n",
      "Epoch: 1, step: 113 / 281, loss: 1.7164734985712355\n",
      "Epoch: 1, step: 121 / 281, loss: 1.8093441583154615\n",
      "Epoch: 1, step: 129 / 281, loss: 1.9117966993141544\n",
      "Epoch: 1, step: 137 / 281, loss: 1.917679554463303\n",
      "Epoch: 1, step: 145 / 281, loss: 1.9382521803009098\n",
      "Epoch: 1, step: 153 / 281, loss: 1.904349958292799\n",
      "Epoch: 1, step: 161 / 281, loss: 1.8984863714586875\n",
      "Epoch: 1, step: 169 / 281, loss: 1.8808328185737486\n",
      "Epoch: 1, step: 177 / 281, loss: 1.828675922111603\n",
      "Epoch: 1, step: 185 / 281, loss: 1.8255564526126191\n",
      "Epoch: 1, step: 193 / 281, loss: 1.803989867549486\n",
      "Epoch: 1, step: 201 / 281, loss: 1.7870673638819463\n",
      "Epoch: 1, step: 209 / 281, loss: 1.770161512722239\n",
      "Epoch: 1, step: 217 / 281, loss: 1.7472430271212407\n",
      "Epoch: 1, step: 225 / 281, loss: 1.7171869070000119\n",
      "Epoch: 1, step: 233 / 281, loss: 1.7169777189457365\n",
      "Epoch: 1, step: 241 / 281, loss: 1.7186900012473347\n",
      "Epoch: 1, step: 249 / 281, loss: 1.7136775334197354\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6892140907768145\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6986503168097082\n",
      "Epoch: 1, step: 273 / 281, loss: 1.706849603753387\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6964931444553293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "Epoch: 2, step: 1 / 281, loss: 0.9903404712677002\n",
      "Epoch: 2, step: 9 / 281, loss: 1.2091296911239624\n",
      "Epoch: 2, step: 17 / 281, loss: 1.2393223608241362\n",
      "Epoch: 2, step: 25 / 281, loss: 1.4782209968566895\n",
      "Epoch: 2, step: 33 / 281, loss: 1.306702633247231\n",
      "Epoch: 2, step: 41 / 281, loss: 1.8242759279361584\n",
      "Epoch: 2, step: 49 / 281, loss: 1.6870434719080827\n",
      "Epoch: 2, step: 57 / 281, loss: 1.7964918945442165\n",
      "Epoch: 2, step: 65 / 281, loss: 1.912631487617126\n",
      "Epoch: 2, step: 73 / 281, loss: 1.8508511142779702\n",
      "Epoch: 2, step: 81 / 281, loss: 1.8840244005859634\n",
      "Epoch: 2, step: 89 / 281, loss: 1.8810518161299523\n",
      "Epoch: 2, step: 97 / 281, loss: 1.924387781736777\n",
      "Epoch: 2, step: 105 / 281, loss: 1.8459877461194991\n",
      "Epoch: 2, step: 113 / 281, loss: 1.8139593773974783\n",
      "Epoch: 2, step: 121 / 281, loss: 1.7698975948016507\n",
      "Epoch: 2, step: 129 / 281, loss: 1.7190615355737449\n",
      "Epoch: 2, step: 137 / 281, loss: 1.7104708726932532\n",
      "Epoch: 2, step: 145 / 281, loss: 1.6974194407976906\n",
      "Epoch: 2, step: 153 / 281, loss: 1.6560666242163944\n",
      "Epoch: 2, step: 161 / 281, loss: 1.6456401289342353\n",
      "Epoch: 2, step: 169 / 281, loss: 1.6244895293338764\n",
      "Epoch: 2, step: 177 / 281, loss: 1.658791449868073\n",
      "Epoch: 2, step: 185 / 281, loss: 1.663755412117855\n",
      "Epoch: 2, step: 193 / 281, loss: 1.6330269659275836\n",
      "Epoch: 2, step: 201 / 281, loss: 1.647969593826811\n",
      "Epoch: 2, step: 209 / 281, loss: 1.6376671994274312\n",
      "Epoch: 2, step: 217 / 281, loss: 1.6328679201652379\n",
      "Epoch: 2, step: 225 / 281, loss: 1.6198144839207331\n",
      "Epoch: 2, step: 233 / 281, loss: 1.6200466218680272\n",
      "Epoch: 2, step: 241 / 281, loss: 1.6175446902320594\n",
      "Epoch: 2, step: 249 / 281, loss: 1.6030388390682788\n",
      "Epoch: 2, step: 257 / 281, loss: 1.5985633946578326\n",
      "Epoch: 2, step: 265 / 281, loss: 1.610979183327477\n",
      "Epoch: 2, step: 273 / 281, loss: 1.6157172444539192\n",
      "Epoch: 2, step: 281 / 281, loss: 1.6013490507293002\n",
      "1.0\n",
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "# non-pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(3):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d8e9155b-23e4-452e-bf8c-060593e257b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 2.7592720985412598\n",
      "Epoch: 0, step: 9 / 281, loss: 2.0186812612745495\n",
      "Epoch: 0, step: 17 / 281, loss: 2.0448199720943676\n",
      "Epoch: 0, step: 25 / 281, loss: 1.946508674621582\n",
      "Epoch: 0, step: 33 / 281, loss: 1.8931593822710442\n",
      "Epoch: 0, step: 41 / 281, loss: 1.893749219615285\n",
      "Epoch: 0, step: 49 / 281, loss: 1.892821985848096\n",
      "Epoch: 0, step: 57 / 281, loss: 1.9896142169048912\n",
      "Epoch: 0, step: 65 / 281, loss: 1.8508722672095665\n",
      "Epoch: 0, step: 73 / 281, loss: 1.9114093437586746\n",
      "Epoch: 0, step: 81 / 281, loss: 1.9593559150342588\n",
      "Epoch: 0, step: 89 / 281, loss: 1.9997915217045987\n",
      "Epoch: 0, step: 97 / 281, loss: 1.9489044049351485\n",
      "Epoch: 0, step: 105 / 281, loss: 1.9180229425430297\n",
      "Epoch: 0, step: 113 / 281, loss: 1.9272019588841802\n",
      "Epoch: 0, step: 121 / 281, loss: 1.9498930420757326\n",
      "Epoch: 0, step: 129 / 281, loss: 1.9260694749595584\n",
      "Epoch: 0, step: 137 / 281, loss: 1.9041858955021322\n",
      "Epoch: 0, step: 145 / 281, loss: 1.9132682200135855\n",
      "Epoch: 0, step: 153 / 281, loss: 1.954425526600258\n",
      "Epoch: 0, step: 161 / 281, loss: 1.941598331706124\n",
      "Epoch: 0, step: 169 / 281, loss: 1.9296720733303996\n",
      "Epoch: 0, step: 177 / 281, loss: 1.9129598477465959\n",
      "Epoch: 0, step: 185 / 281, loss: 1.9176070490398922\n",
      "Epoch: 0, step: 193 / 281, loss: 1.9164788074443995\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8969166800750428\n",
      "Epoch: 0, step: 209 / 281, loss: 1.9015801939667698\n",
      "Epoch: 0, step: 217 / 281, loss: 1.9003200267317109\n",
      "Epoch: 0, step: 225 / 281, loss: 1.9030110602908665\n",
      "Epoch: 0, step: 233 / 281, loss: 1.9123343500456584\n",
      "Epoch: 0, step: 241 / 281, loss: 1.9053551694416901\n",
      "Epoch: 0, step: 249 / 281, loss: 1.892970606864217\n",
      "Epoch: 0, step: 257 / 281, loss: 1.883804381473519\n",
      "Epoch: 0, step: 265 / 281, loss: 1.8854630874013\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8779546916484833\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8755732964578473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "Epoch: 1, step: 1 / 281, loss: 2.830392599105835\n",
      "Epoch: 1, step: 9 / 281, loss: 1.83727731804053\n",
      "Epoch: 1, step: 17 / 281, loss: 1.517961924566942\n",
      "Epoch: 1, step: 25 / 281, loss: 1.7089318430423737\n",
      "Epoch: 1, step: 33 / 281, loss: 1.7376287480195363\n",
      "Epoch: 1, step: 41 / 281, loss: 1.6466180776677481\n",
      "Epoch: 1, step: 49 / 281, loss: 1.5208125582763128\n",
      "Epoch: 1, step: 57 / 281, loss: 1.5473935023734444\n",
      "Epoch: 1, step: 65 / 281, loss: 1.5701666919084696\n",
      "Epoch: 1, step: 73 / 281, loss: 1.5076581325433025\n",
      "Epoch: 1, step: 81 / 281, loss: 1.4787089151364785\n",
      "Epoch: 1, step: 89 / 281, loss: 1.4306895120090313\n",
      "Epoch: 1, step: 97 / 281, loss: 1.4951415943730737\n",
      "Epoch: 1, step: 105 / 281, loss: 1.4685016708714622\n",
      "Epoch: 1, step: 113 / 281, loss: 1.4720258272327154\n",
      "Epoch: 1, step: 121 / 281, loss: 1.4305070916975826\n",
      "Epoch: 1, step: 129 / 281, loss: 1.4437457232974296\n",
      "Epoch: 1, step: 137 / 281, loss: 1.465366628483264\n",
      "Epoch: 1, step: 145 / 281, loss: 1.5115189178236599\n",
      "Epoch: 1, step: 153 / 281, loss: 1.5301300992373548\n",
      "Epoch: 1, step: 161 / 281, loss: 1.5444391965866089\n",
      "Epoch: 1, step: 169 / 281, loss: 1.5663073895245614\n",
      "Epoch: 1, step: 177 / 281, loss: 1.5574320655758098\n",
      "Epoch: 1, step: 185 / 281, loss: 1.54351671321972\n",
      "Epoch: 1, step: 193 / 281, loss: 1.5572934641739247\n",
      "Epoch: 1, step: 201 / 281, loss: 1.5568074652211583\n",
      "Epoch: 1, step: 209 / 281, loss: 1.6085323102451397\n",
      "Epoch: 1, step: 217 / 281, loss: 1.6030795056424383\n",
      "Epoch: 1, step: 225 / 281, loss: 1.6284784177939098\n",
      "Epoch: 1, step: 233 / 281, loss: 1.6409472724654643\n",
      "Epoch: 1, step: 241 / 281, loss: 1.6476468774045652\n",
      "Epoch: 1, step: 249 / 281, loss: 1.6627607667541886\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6740873199724502\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6686845269967925\n",
      "Epoch: 1, step: 273 / 281, loss: 1.6495630288080418\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6336136016981457\n",
      "0.8\n",
      "0.4444444444444444\n",
      "Epoch: 2, step: 1 / 281, loss: 1.9566435813903809\n",
      "Epoch: 2, step: 9 / 281, loss: 0.6218284832106696\n",
      "Epoch: 2, step: 17 / 281, loss: 0.8591296120601541\n",
      "Epoch: 2, step: 25 / 281, loss: 0.9395977878570556\n",
      "Epoch: 2, step: 33 / 281, loss: 1.0163105690118037\n",
      "Epoch: 2, step: 41 / 281, loss: 1.1512325587796002\n",
      "Epoch: 2, step: 49 / 281, loss: 1.2716707350039969\n",
      "Epoch: 2, step: 57 / 281, loss: 1.3145540957910973\n",
      "Epoch: 2, step: 65 / 281, loss: 1.495930413557933\n",
      "Epoch: 2, step: 73 / 281, loss: 1.5464335586110207\n",
      "Epoch: 2, step: 81 / 281, loss: 1.5987218224707944\n",
      "Epoch: 2, step: 89 / 281, loss: 1.6002283618691262\n",
      "Epoch: 2, step: 97 / 281, loss: 1.499078758598603\n",
      "Epoch: 2, step: 105 / 281, loss: 1.5538509062358312\n",
      "Epoch: 2, step: 113 / 281, loss: 1.5527686787917552\n",
      "Epoch: 2, step: 121 / 281, loss: 1.5395956540649587\n",
      "Epoch: 2, step: 129 / 281, loss: 1.5586452919614406\n",
      "Epoch: 2, step: 137 / 281, loss: 1.5698779089389927\n",
      "Epoch: 2, step: 145 / 281, loss: 1.5954475385361704\n",
      "Epoch: 2, step: 153 / 281, loss: 1.618183017458791\n",
      "Epoch: 2, step: 161 / 281, loss: 1.633291520224595\n",
      "Epoch: 2, step: 169 / 281, loss: 1.640971308893706\n",
      "Epoch: 2, step: 177 / 281, loss: 1.6318805988057186\n",
      "Epoch: 2, step: 185 / 281, loss: 1.6292415940278284\n",
      "Epoch: 2, step: 193 / 281, loss: 1.6224725637874455\n",
      "Epoch: 2, step: 201 / 281, loss: 1.6479508011643567\n",
      "Epoch: 2, step: 209 / 281, loss: 1.6107231258419141\n",
      "Epoch: 2, step: 217 / 281, loss: 1.5947898429590985\n",
      "Epoch: 2, step: 225 / 281, loss: 1.5658624496393734\n",
      "Epoch: 2, step: 233 / 281, loss: 1.5498195792920089\n",
      "Epoch: 2, step: 241 / 281, loss: 1.5246574107047433\n",
      "Epoch: 2, step: 249 / 281, loss: 1.5199010464321658\n",
      "Epoch: 2, step: 257 / 281, loss: 1.4800316181164308\n",
      "Epoch: 2, step: 265 / 281, loss: 1.45627334688632\n",
      "Epoch: 2, step: 273 / 281, loss: 1.4560431795733753\n",
      "Epoch: 2, step: 281 / 281, loss: 1.4617534809318302\n",
      "0.41025641025641024\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# non-pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(3):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2844a3c0-fdd3-415e-abf5-f6c97604ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 1.7101575136184692\n",
      "Epoch: 0, step: 5 / 281, loss: 1.4812070608139039\n",
      "Epoch: 0, step: 9 / 281, loss: 1.3079716364542644\n",
      "Epoch: 0, step: 13 / 281, loss: 1.823077495281513\n",
      "Epoch: 0, step: 17 / 281, loss: 1.6630467527052935\n",
      "Epoch: 0, step: 21 / 281, loss: 1.8416676975431896\n",
      "Epoch: 0, step: 25 / 281, loss: 1.9523288106918335\n",
      "Epoch: 0, step: 29 / 281, loss: 2.014886194262011\n",
      "Epoch: 0, step: 33 / 281, loss: 1.8870762586593628\n",
      "Epoch: 0, step: 37 / 281, loss: 1.8546467729516931\n",
      "Epoch: 0, step: 41 / 281, loss: 1.9063204148920572\n",
      "Epoch: 0, step: 45 / 281, loss: 1.9453119436899822\n",
      "Epoch: 0, step: 49 / 281, loss: 2.035807441691963\n",
      "Epoch: 0, step: 53 / 281, loss: 1.9134045974263605\n",
      "Epoch: 0, step: 57 / 281, loss: 1.9582718485280086\n",
      "Epoch: 0, step: 61 / 281, loss: 1.9239012882357738\n",
      "Epoch: 0, step: 65 / 281, loss: 1.876353223507221\n",
      "Epoch: 0, step: 69 / 281, loss: 1.8896263388619907\n",
      "Epoch: 0, step: 73 / 281, loss: 1.8255659619422808\n",
      "Epoch: 0, step: 77 / 281, loss: 1.8008806953182468\n",
      "Epoch: 0, step: 81 / 281, loss: 1.816748367415534\n",
      "Epoch: 0, step: 85 / 281, loss: 1.8048715310938217\n",
      "Epoch: 0, step: 89 / 281, loss: 1.8487545975138633\n",
      "Epoch: 0, step: 93 / 281, loss: 1.8526088909436298\n",
      "Epoch: 0, step: 97 / 281, loss: 1.92378180543172\n",
      "Epoch: 0, step: 101 / 281, loss: 1.9093344825329166\n",
      "Epoch: 0, step: 105 / 281, loss: 1.8947493621281215\n",
      "Epoch: 0, step: 109 / 281, loss: 1.8812468511248948\n",
      "Epoch: 0, step: 113 / 281, loss: 1.8394868247276914\n",
      "Epoch: 0, step: 117 / 281, loss: 1.8500948186613555\n",
      "Epoch: 0, step: 121 / 281, loss: 1.8305239431129015\n",
      "Epoch: 0, step: 125 / 281, loss: 1.826094289779663\n",
      "Epoch: 0, step: 129 / 281, loss: 1.8408726869627487\n",
      "Epoch: 0, step: 133 / 281, loss: 1.819471292029646\n",
      "Epoch: 0, step: 137 / 281, loss: 1.808077679063282\n",
      "Epoch: 0, step: 141 / 281, loss: 1.8119060088556709\n",
      "Epoch: 0, step: 145 / 281, loss: 1.8129215495339754\n",
      "Epoch: 0, step: 149 / 281, loss: 1.804862349625402\n",
      "Epoch: 0, step: 153 / 281, loss: 1.8162116217457391\n",
      "Epoch: 0, step: 157 / 281, loss: 1.8620044600432086\n",
      "Epoch: 0, step: 161 / 281, loss: 1.8697025598206134\n",
      "Epoch: 0, step: 165 / 281, loss: 1.8779466173865578\n",
      "Epoch: 0, step: 169 / 281, loss: 1.8584536610270392\n",
      "Epoch: 0, step: 173 / 281, loss: 1.8783020993877697\n",
      "Epoch: 0, step: 177 / 281, loss: 1.8721296187848022\n",
      "Epoch: 0, step: 181 / 281, loss: 1.88144066123014\n",
      "Epoch: 0, step: 185 / 281, loss: 1.8965373960701195\n",
      "Epoch: 0, step: 189 / 281, loss: 1.897290414603299\n",
      "Epoch: 0, step: 193 / 281, loss: 1.9000454696348912\n",
      "Epoch: 0, step: 197 / 281, loss: 1.8857828221345312\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8698130395281967\n",
      "Epoch: 0, step: 205 / 281, loss: 1.8747228058373056\n",
      "Epoch: 0, step: 209 / 281, loss: 1.8684669359448993\n",
      "Epoch: 0, step: 213 / 281, loss: 1.8781616046954768\n",
      "Epoch: 0, step: 217 / 281, loss: 1.8972996728760856\n",
      "Epoch: 0, step: 221 / 281, loss: 1.9091477197219884\n",
      "Epoch: 0, step: 225 / 281, loss: 1.898909486664666\n",
      "Epoch: 0, step: 229 / 281, loss: 1.8769738999516683\n",
      "Epoch: 0, step: 233 / 281, loss: 1.8721908865568464\n",
      "Epoch: 0, step: 237 / 281, loss: 1.874906787137945\n",
      "Epoch: 0, step: 241 / 281, loss: 1.8699842181937822\n",
      "Epoch: 0, step: 245 / 281, loss: 1.8699068813907858\n",
      "Epoch: 0, step: 249 / 281, loss: 1.8704833012508102\n",
      "Epoch: 0, step: 253 / 281, loss: 1.8746088926971194\n",
      "Epoch: 0, step: 257 / 281, loss: 1.868460552237841\n",
      "Epoch: 0, step: 261 / 281, loss: 1.8858801925776105\n",
      "Epoch: 0, step: 265 / 281, loss: 1.888021432228808\n",
      "Epoch: 0, step: 269 / 281, loss: 1.8917261047434186\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8970803096617535\n",
      "Epoch: 0, step: 277 / 281, loss: 1.8719227161218113\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8690247720246638\n",
      "0.2807017543859649\n",
      "0.8888888888888888\n",
      "Epoch: 1, step: 1 / 281, loss: 1.5805689096450806\n",
      "Epoch: 1, step: 5 / 281, loss: 2.3520138025283814\n",
      "Epoch: 1, step: 9 / 281, loss: 1.8644792238871257\n",
      "Epoch: 1, step: 13 / 281, loss: 1.9405400111125066\n",
      "Epoch: 1, step: 17 / 281, loss: 2.0066891628153183\n",
      "Epoch: 1, step: 21 / 281, loss: 1.9232813630785262\n",
      "Epoch: 1, step: 25 / 281, loss: 1.9817783546447754\n",
      "Epoch: 1, step: 29 / 281, loss: 1.9968116530056657\n",
      "Epoch: 1, step: 33 / 281, loss: 1.7690335566347295\n",
      "Epoch: 1, step: 37 / 281, loss: 1.724903670517174\n",
      "Epoch: 1, step: 41 / 281, loss: 1.7363584739405935\n",
      "Epoch: 1, step: 45 / 281, loss: 1.6664864791764153\n",
      "Epoch: 1, step: 49 / 281, loss: 1.7415786957254216\n",
      "Epoch: 1, step: 53 / 281, loss: 1.6978700745780513\n",
      "Epoch: 1, step: 57 / 281, loss: 1.6629301539638586\n",
      "Epoch: 1, step: 61 / 281, loss: 1.6321488814275773\n",
      "Epoch: 1, step: 65 / 281, loss: 1.6706989623033084\n",
      "Epoch: 1, step: 69 / 281, loss: 1.6601819650850433\n",
      "Epoch: 1, step: 73 / 281, loss: 1.5922527954186478\n",
      "Epoch: 1, step: 77 / 281, loss: 1.630484873211229\n",
      "Epoch: 1, step: 81 / 281, loss: 1.6899259086744285\n",
      "Epoch: 1, step: 85 / 281, loss: 1.7130673103472767\n",
      "Epoch: 1, step: 89 / 281, loss: 1.6769185524977994\n",
      "Epoch: 1, step: 93 / 281, loss: 1.6710193634674113\n",
      "Epoch: 1, step: 97 / 281, loss: 1.6818949251445299\n",
      "Epoch: 1, step: 101 / 281, loss: 1.6756939560470014\n",
      "Epoch: 1, step: 105 / 281, loss: 1.6679599537735894\n",
      "Epoch: 1, step: 109 / 281, loss: 1.6757546091845277\n",
      "Epoch: 1, step: 113 / 281, loss: 1.6506089518028022\n",
      "Epoch: 1, step: 117 / 281, loss: 1.6752598945401673\n",
      "Epoch: 1, step: 121 / 281, loss: 1.6495847566561266\n",
      "Epoch: 1, step: 125 / 281, loss: 1.621935699224472\n",
      "Epoch: 1, step: 129 / 281, loss: 1.6029541767382807\n",
      "Epoch: 1, step: 133 / 281, loss: 1.594612638529082\n",
      "Epoch: 1, step: 137 / 281, loss: 1.5528890201210106\n",
      "Epoch: 1, step: 141 / 281, loss: 1.5487046396055966\n",
      "Epoch: 1, step: 145 / 281, loss: 1.5707697985501126\n",
      "Epoch: 1, step: 149 / 281, loss: 1.5850393638114801\n",
      "Epoch: 1, step: 153 / 281, loss: 1.5994104507312277\n",
      "Epoch: 1, step: 157 / 281, loss: 1.5986018478870392\n",
      "Epoch: 1, step: 161 / 281, loss: 1.5790239159735093\n",
      "Epoch: 1, step: 165 / 281, loss: 1.595349197134827\n",
      "Epoch: 1, step: 169 / 281, loss: 1.6148373355879586\n",
      "Epoch: 1, step: 173 / 281, loss: 1.597403631217218\n",
      "Epoch: 1, step: 177 / 281, loss: 1.5824357926172052\n",
      "Epoch: 1, step: 181 / 281, loss: 1.5889694646247843\n",
      "Epoch: 1, step: 185 / 281, loss: 1.5809568393874813\n",
      "Epoch: 1, step: 189 / 281, loss: 1.5835322956874889\n",
      "Epoch: 1, step: 193 / 281, loss: 1.5854175419696255\n",
      "Epoch: 1, step: 197 / 281, loss: 1.5532263228433387\n",
      "Epoch: 1, step: 201 / 281, loss: 1.561250815788905\n",
      "Epoch: 1, step: 205 / 281, loss: 1.5929344027507595\n",
      "Epoch: 1, step: 209 / 281, loss: 1.5854551582530354\n",
      "Epoch: 1, step: 213 / 281, loss: 1.609870924776149\n",
      "Epoch: 1, step: 217 / 281, loss: 1.5949623973413547\n",
      "Epoch: 1, step: 221 / 281, loss: 1.5994621611019066\n",
      "Epoch: 1, step: 225 / 281, loss: 1.6134570403893789\n",
      "Epoch: 1, step: 229 / 281, loss: 1.605828330636545\n",
      "Epoch: 1, step: 233 / 281, loss: 1.6257209651204139\n",
      "Epoch: 1, step: 237 / 281, loss: 1.6223461366403957\n",
      "Epoch: 1, step: 241 / 281, loss: 1.645769751418181\n",
      "Epoch: 1, step: 245 / 281, loss: 1.6488633924601028\n",
      "Epoch: 1, step: 249 / 281, loss: 1.6472500603361782\n",
      "Epoch: 1, step: 253 / 281, loss: 1.6598360587956877\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6705256498741268\n",
      "Epoch: 1, step: 261 / 281, loss: 1.6765508713393376\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6644336664451742\n",
      "Epoch: 1, step: 269 / 281, loss: 1.6747311340388755\n",
      "Epoch: 1, step: 273 / 281, loss: 1.6680650042963552\n",
      "Epoch: 1, step: 277 / 281, loss: 1.665689977928189\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6657074532899143\n",
      "0.8333333333333334\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(2):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b90e2ecf-3fbf-478c-b589-137136abadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc955d-c1cc-4bbe-b1ce-b6c47fd011d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
