{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1c2e181-f2ad-4bb3-8583-796317016f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MINIT.minit import MINiT\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc811d6-933d-49c4-8921-df5e1513e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1301/9726765.py:2: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  adni_merge_2 = pd.read_csv('ADNIMERGE.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "adni_merge_1 = pd.read_csv('our_subj_adnimerge.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n",
    "adni_merge_2 = pd.read_csv('ADNIMERGE.csv').sort_values(['PTID', 'EXAMDATE']).reset_index(drop=True)\n",
    "adni_merge_1 = adni_merge_1[['PTID', 'VISCODE', 'DX_bl']]\n",
    "adni_merge_2 = adni_merge_2[['PTID', 'VISCODE', 'DX_bl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6a83d0-f4d0-4a62-9c7b-54774fad90ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1301/2513726996.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Counter(pd.read_csv('ADNIMERGE.csv')['DX_bl'].values)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'CN': 4512,\n",
       "         'AD': 1667,\n",
       "         'LMCI': 5037,\n",
       "         'SMC': 1037,\n",
       "         'EMCI': 2740,\n",
       "         nan: 10})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# какое количество классов во всем ADNI\n",
    "from collections import Counter\n",
    "Counter(pd.read_csv('ADNIMERGE.csv')['DX_bl'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5384e4be-6dd6-4040-8408-e13aca7b8bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'CN': 775, 'AD': 409, 'LMCI': 1430})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# какое количество классов в нашем сэмпле ADNI\n",
    "Counter(pd.read_csv('our_subj_adnimerge.csv')['DX_bl'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b9a93-f90d-4dda-bc9b-a29209abb852",
   "metadata": {},
   "source": [
    "# Делаем dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45a4fab4-c919-4de1-80b9-abf16f84f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/druzhininapo/nfs/caps/subjects/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e97ce218-1531-4c7e-95a0-314953ad2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(adni_merge, resize=64):\n",
    "    resizer_64 = monai.transforms.Resize((resize, resize, resize))\n",
    "    label2num = {\n",
    "        'AD': 1,\n",
    "        'CN': 0,\n",
    "    }\n",
    "    dataset = {}\n",
    "    for subj in tqdm(np.unique(adni_merge_1[['PTID']].values)):\n",
    "        subj_path = subj.replace('_', '')\n",
    "        for ses in os.listdir(os.path.join(BASE_PATH, f\"sub-ADNI{subj_path}\")):\n",
    "            subj_samples = adni_merge[adni_merge['PTID'] == subj]\n",
    "            if subj_samples[subj_samples['VISCODE'] == ses.split('-')[1].lower()].shape[0] == 0:\n",
    "                continue\n",
    "            label_text = subj_samples[subj_samples['VISCODE'] == ses.split('-')[1].lower()]['DX_bl'].values[0]\n",
    "            if label_text not in label2num:\n",
    "                continue\n",
    "            \n",
    "            path_to_tensor = os.path.join(BASE_PATH, f\"sub-ADNI{subj_path}\", ses, 'deeplearning_prepare_data/image_based/t1_linear/')\n",
    "            image_tensor = torch.load(os.path.join(path_to_tensor, os.listdir(path_to_tensor)[0]))\n",
    "            \n",
    "            if resize:\n",
    "                image_tensor = resizer_64(image_tensor).get_array()\n",
    "\n",
    "            if subj in dataset:\n",
    "                dataset[subj].append((image_tensor, label2num[label_text]))\n",
    "            else:\n",
    "                dataset[subj] = [(image_tensor, label2num[label_text])]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85ee916e-49b1-46a1-8a39-eae703777677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 771/771 [03:12<00:00,  4.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = make_dataset(adni_merge_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98416640-8003-4fab-8406-ec0aa363f0ff",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be29ccfb-bbad-4d1a-9cc2-492d460005fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        'Initialization'\n",
    "        self.labels = y\n",
    "        self.X = X # Maps index to id\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        X = torch.tensor(self.X[index])\n",
    "\n",
    "        return {'tensor': X, 'label': self.labels[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "475ccd6c-44ab-44d5-8a8c-725fc8131953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def get_dataloder(dataset_dict, batch_train_size=4, n_splits=5, verbose=True):\n",
    "\n",
    "    def make_tensors(set_subj):\n",
    "        X = []\n",
    "        y = []\n",
    "        for subj in set_subj:\n",
    "            for tensor, label in dataset_dict[subj]:\n",
    "                X.append(tensor)\n",
    "                y.append(label)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    all_keys_subj = np.sort(list(dataset_dict.keys()))\n",
    "    kfold = KFold(n_splits=N_SPLITS, random_state=29, shuffle=True)\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(all_keys_subj)):\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Number fold: {i+1}\")\n",
    "    \n",
    "        X_train, y_train = make_tensors(all_keys_subj[train_idx])\n",
    "        X_test, y_test = make_tensors(all_keys_subj[test_idx])\n",
    "\n",
    "        mri_dataset_train = MRIDataset(X_train, y_train)\n",
    "        mri_dataset_test = MRIDataset(X_test, y_test)\n",
    "\n",
    "        mri_dataloader_train = torch.utils.data.DataLoader(mri_dataset_train, batch_size=batch_train_size, shuffle=True)\n",
    "        mri_dataloader_test = torch.utils.data.DataLoader(mri_dataset_test, batch_size=1, shuffle=False)\n",
    "    \n",
    "        yield mri_dataloader_train, mri_dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64463c81-a0f4-4d5b-9de6-bf0ba7caf3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vit(dataset_dict, epoch_num=3, thr=0.5, use_checkpoint=False):\n",
    "    precision_folds = []\n",
    "    recall_folds = []\n",
    "    auc_folds = []\n",
    "    \n",
    "    for train_dataloader, test_dataloader in get_dataloder(dataset_dict):\n",
    "\n",
    "        net = MINiT(\n",
    "            block_size = 16,\n",
    "            image_size = 64,\n",
    "            patch_size = 8,\n",
    "            num_classes = 1,\n",
    "            channels = 1,\n",
    "            dim = 256,\n",
    "            depth = 6,\n",
    "            heads = 4,\n",
    "            mlp_dim = 309\n",
    "        ).to(device)\n",
    "\n",
    "        if use_checkpoint:\n",
    "            checkpoint = torch.load(\"MINIT/minit.pt\")\n",
    "            state = checkpoint['model_state_dict']\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=5e-4)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        precision_folds = []\n",
    "        recall_folds = []\n",
    "        auc_folds = []\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            print(f\"Train step\")\n",
    "\n",
    "            net.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            for i, batch in enumerate(mri_dataloader_train):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(brain_img)\n",
    "                loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "                loss_calc.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_train_loss += loss_calc.item()\n",
    "                if i % 24 == 0:\n",
    "                    print(f\"Epoch: {epoch+1}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "            print(f\"Test step\")\n",
    "\n",
    "            net.eval()\n",
    "            labels_pred = []\n",
    "            logits_pred = []\n",
    "            for i, batch in enumerate(mri_dataloader_test):\n",
    "                brain_img = batch['tensor'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "                    logits_pred.append(output_prob)\n",
    "\n",
    "                    if output_prob > thr:\n",
    "                        labels_pred.append(1)\n",
    "                    else:\n",
    "                        labels_pred.append(0)\n",
    "\n",
    "                        \n",
    "            precision_score_fold = precision_score(y_test, labels_pred)\n",
    "            recall_score_fold = recall_score(y_test, labels_pred)\n",
    "            auc_fold = roc_auc_score(y_test, logits_pred)\n",
    "            \n",
    "            precision_folds.append(precision_score_fold)\n",
    "            recall_folds.append(recall_score_fold)\n",
    "            auc_folds.append(auc_fold)\n",
    "            \n",
    "            print(f\"Precision: {precision_score_fold}\")\n",
    "            print(f\"Recall: {recall_score_fold}\")  \n",
    "            print(f\"AUC: {auc_fold}\")  \n",
    "            \n",
    "    return precision_folds, recall_folds, auc_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c1e7a-6e73-4803-b7a5-f73fa9a3b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number fold: 1\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 2.783334732055664\n",
      "Epoch: 1, step: 25 / 232, loss: 2.2007543087005614\n",
      "Epoch: 1, step: 49 / 232, loss: 2.1319573217508743\n",
      "Epoch: 1, step: 73 / 232, loss: 2.030388921091001\n",
      "Epoch: 1, step: 97 / 232, loss: 1.9958675497585965\n",
      "Epoch: 1, step: 121 / 232, loss: 1.959923521546293\n",
      "Epoch: 1, step: 145 / 232, loss: 1.9922145991489806\n",
      "Epoch: 1, step: 169 / 232, loss: 2.0103664786152584\n",
      "Epoch: 1, step: 193 / 232, loss: 1.9885836883684513\n",
      "Epoch: 1, step: 217 / 232, loss: 2.0080937120359614\n",
      "Test step\n",
      "Precision: 0.2265625\n",
      "Recall: 0.9666666666666667\n",
      "AUC: 0.5659090909090908\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 1.5438249111175537\n",
      "Epoch: 2, step: 25 / 232, loss: 2.3925910663604735\n",
      "Epoch: 2, step: 49 / 232, loss: 1.9885262992917274\n",
      "Epoch: 2, step: 73 / 232, loss: 1.9302974800540977\n",
      "Epoch: 2, step: 97 / 232, loss: 1.8899679380593841\n",
      "Epoch: 2, step: 121 / 232, loss: 1.8538431790003107\n",
      "Epoch: 2, step: 145 / 232, loss: 1.8560467157898277\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8495672018041271\n",
      "Epoch: 2, step: 193 / 232, loss: 1.890122185794183\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9334826508562686\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6626262626262626\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 1.3412561416625977\n",
      "Epoch: 3, step: 25 / 232, loss: 2.049325551986694\n",
      "Epoch: 3, step: 49 / 232, loss: 1.9530858415730146\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9508703334690773\n",
      "Epoch: 3, step: 97 / 232, loss: 1.9271789998123325\n",
      "Epoch: 3, step: 121 / 232, loss: 1.890053813615121\n",
      "Epoch: 3, step: 145 / 232, loss: 1.8553521908562758\n",
      "Epoch: 3, step: 169 / 232, loss: 1.7850371360911068\n",
      "Epoch: 3, step: 193 / 232, loss: 1.7678617848749296\n",
      "Epoch: 3, step: 217 / 232, loss: 1.775182299951117\n",
      "Test step\n",
      "Precision: 1.0\n",
      "Recall: 0.03333333333333333\n",
      "AUC: 0.6312289562289563\n",
      "Number fold: 2\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 4.139474868774414\n",
      "Epoch: 1, step: 25 / 232, loss: 1.527468945980072\n",
      "Epoch: 1, step: 49 / 232, loss: 1.9085381286484855\n",
      "Epoch: 1, step: 73 / 232, loss: 1.8276267043531758\n",
      "Epoch: 1, step: 97 / 232, loss: 1.8923038047613556\n",
      "Epoch: 1, step: 121 / 232, loss: 1.8316061043542278\n",
      "Epoch: 1, step: 145 / 232, loss: 1.9381205090161027\n",
      "Epoch: 1, step: 169 / 232, loss: 2.031438511504224\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0218102579907433\n",
      "Epoch: 1, step: 217 / 232, loss: 2.007361127346891\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5017676767676768\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 1.3590525388717651\n",
      "Epoch: 2, step: 25 / 232, loss: 1.3724038290977478\n",
      "Epoch: 2, step: 49 / 232, loss: 1.6351589426702382\n",
      "Epoch: 2, step: 73 / 232, loss: 1.8877643232476222\n",
      "Epoch: 2, step: 97 / 232, loss: 1.8773271994492442\n",
      "Epoch: 2, step: 121 / 232, loss: 1.8045832630523966\n",
      "Epoch: 2, step: 145 / 232, loss: 1.8390445423537287\n",
      "Epoch: 2, step: 169 / 232, loss: 1.9015236011976322\n",
      "Epoch: 2, step: 193 / 232, loss: 1.930279369953383\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9043542378783775\n",
      "Test step\n",
      "Precision: 0.3364485981308411\n",
      "Recall: 0.6\n",
      "AUC: 0.6622053872053872\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 2.7793192863464355\n",
      "Epoch: 3, step: 25 / 232, loss: 1.9847800016403199\n",
      "Epoch: 3, step: 49 / 232, loss: 1.6903032088766292\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9176592173641676\n",
      "Epoch: 3, step: 97 / 232, loss: 1.9401632793170889\n",
      "Epoch: 3, step: 121 / 232, loss: 1.9340099480526507\n",
      "Epoch: 3, step: 145 / 232, loss: 1.9114162436847029\n",
      "Epoch: 3, step: 169 / 232, loss: 1.8932099583938982\n",
      "Epoch: 3, step: 193 / 232, loss: 1.82838525526573\n",
      "Epoch: 3, step: 217 / 232, loss: 1.8481617070700167\n",
      "Test step\n",
      "Precision: 0.2857142857142857\n",
      "Recall: 0.8666666666666667\n",
      "AUC: 0.6776936026936027\n",
      "Number fold: 3\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 2.7391889095306396\n",
      "Epoch: 1, step: 25 / 232, loss: 2.593211736679077\n",
      "Epoch: 1, step: 49 / 232, loss: 2.2867370381647225\n",
      "Epoch: 1, step: 73 / 232, loss: 2.128644235330085\n",
      "Epoch: 1, step: 97 / 232, loss: 2.14517443573352\n",
      "Epoch: 1, step: 121 / 232, loss: 2.0609294737666106\n",
      "Epoch: 1, step: 145 / 232, loss: 2.067208775980719\n",
      "Epoch: 1, step: 169 / 232, loss: 2.090325967094602\n",
      "Epoch: 1, step: 193 / 232, loss: 2.0703006748090753\n",
      "Epoch: 1, step: 217 / 232, loss: 2.0379411141443913\n",
      "Test step\n",
      "Precision: 0.23255813953488372\n",
      "Recall: 1.0\n",
      "AUC: 0.5142255892255893\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 2.6214747428894043\n",
      "Epoch: 2, step: 25 / 232, loss: 1.9157844734191896\n",
      "Epoch: 2, step: 49 / 232, loss: 1.7250820586875992\n",
      "Epoch: 2, step: 73 / 232, loss: 1.7824561142758146\n",
      "Epoch: 2, step: 97 / 232, loss: 1.8941829054011512\n",
      "Epoch: 2, step: 121 / 232, loss: 1.8635254125457166\n",
      "Epoch: 2, step: 145 / 232, loss: 1.8945290921063258\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8828187004701626\n",
      "Epoch: 2, step: 193 / 232, loss: 1.881724800007331\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9312047300525526\n",
      "Test step\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.13333333333333333\n",
      "AUC: 0.6464646464646465\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 3.7779955863952637\n",
      "Epoch: 3, step: 25 / 232, loss: 2.3844228625297545\n",
      "Epoch: 3, step: 49 / 232, loss: 1.9076980620014423\n",
      "Epoch: 3, step: 73 / 232, loss: 1.9199815351669103\n",
      "Epoch: 3, step: 97 / 232, loss: 1.7925707605696215\n",
      "Epoch: 3, step: 121 / 232, loss: 1.7216991062991875\n",
      "Epoch: 3, step: 145 / 232, loss: 1.8011318712398923\n",
      "Epoch: 3, step: 169 / 232, loss: 1.903223638351147\n",
      "Epoch: 3, step: 193 / 232, loss: 1.8722180057066091\n",
      "Epoch: 3, step: 217 / 232, loss: 1.866334846766863\n",
      "Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6099326599326599\n",
      "Number fold: 4\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 4.156723499298096\n",
      "Epoch: 1, step: 25 / 232, loss: 2.415364990234375\n",
      "Epoch: 1, step: 49 / 232, loss: 2.4104506361241245\n",
      "Epoch: 1, step: 73 / 232, loss: 2.373163540069371\n",
      "Epoch: 1, step: 97 / 232, loss: 2.192198198480704\n",
      "Epoch: 1, step: 121 / 232, loss: 2.1660333797951377\n",
      "Epoch: 1, step: 145 / 232, loss: 2.1821791430999493\n",
      "Epoch: 1, step: 169 / 232, loss: 2.155454390500424\n",
      "Epoch: 1, step: 193 / 232, loss: 2.1221232695283048\n",
      "Epoch: 1, step: 217 / 232, loss: 2.0579833998108787\n",
      "Test step\n",
      "Precision: 0.3088235294117647\n",
      "Recall: 0.35\n",
      "AUC: 0.6324915824915825\n",
      "Train step\n",
      "Epoch: 2, step: 1 / 232, loss: 1.6811665296554565\n",
      "Epoch: 2, step: 25 / 232, loss: 2.390007758140564\n",
      "Epoch: 2, step: 49 / 232, loss: 2.0251454625810896\n",
      "Epoch: 2, step: 73 / 232, loss: 1.9436180922266555\n",
      "Epoch: 2, step: 97 / 232, loss: 1.9692222141113478\n",
      "Epoch: 2, step: 121 / 232, loss: 1.8530534350674999\n",
      "Epoch: 2, step: 145 / 232, loss: 1.847318594209079\n",
      "Epoch: 2, step: 169 / 232, loss: 1.8604529371275704\n",
      "Epoch: 2, step: 193 / 232, loss: 1.8995406328087643\n",
      "Epoch: 2, step: 217 / 232, loss: 1.9132433522681487\n",
      "Test step\n",
      "Precision: 0.5\n",
      "Recall: 0.11666666666666667\n",
      "AUC: 0.7288720538720539\n",
      "Train step\n",
      "Epoch: 3, step: 1 / 232, loss: 1.20745849609375\n",
      "Epoch: 3, step: 25 / 232, loss: 1.4677073502540587\n",
      "Epoch: 3, step: 49 / 232, loss: 1.509994859598121\n",
      "Epoch: 3, step: 73 / 232, loss: 1.5248547494411469\n",
      "Epoch: 3, step: 97 / 232, loss: 1.6274197384254219\n",
      "Epoch: 3, step: 121 / 232, loss: 1.6650865851354992\n",
      "Epoch: 3, step: 145 / 232, loss: 1.6481404925214833\n",
      "Epoch: 3, step: 169 / 232, loss: 1.7278407000931058\n",
      "Epoch: 3, step: 193 / 232, loss: 1.7766240841366467\n",
      "Epoch: 3, step: 217 / 232, loss: 1.7767987493683117\n",
      "Test step\n",
      "Precision: 0.3944954128440367\n",
      "Recall: 0.7166666666666667\n",
      "AUC: 0.7223905723905724\n",
      "Number fold: 5\n",
      "Train step\n",
      "Epoch: 1, step: 1 / 232, loss: 1.3877699375152588\n",
      "Epoch: 1, step: 25 / 232, loss: 2.097631964683533\n",
      "Epoch: 1, step: 49 / 232, loss: 2.2080087783385296\n"
     ]
    }
   ],
   "source": [
    "precision_folds, recall_folds, auc_folds = train_vit(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a99c3-61d0-41f3-a9cb-acf66282274b",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3ae17632-cb29-4096-94c8-f77d6c022df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 0.0\n",
      "Epoch: 0, step: 9 / 281, loss: 2.394197834862603\n",
      "Epoch: 0, step: 17 / 281, loss: 2.000979598830728\n",
      "Epoch: 0, step: 25 / 281, loss: 2.072249717712402\n",
      "Epoch: 0, step: 33 / 281, loss: 1.838512633786057\n",
      "Epoch: 0, step: 41 / 281, loss: 1.8390611381065556\n",
      "Epoch: 0, step: 49 / 281, loss: 1.676484385315253\n",
      "Epoch: 0, step: 57 / 281, loss: 1.7525349311661302\n",
      "Epoch: 0, step: 65 / 281, loss: 1.7216973625696623\n",
      "Epoch: 0, step: 73 / 281, loss: 1.7372005336905179\n",
      "Epoch: 0, step: 81 / 281, loss: 1.7519290660634452\n",
      "Epoch: 0, step: 89 / 281, loss: 1.7796537909614907\n",
      "Epoch: 0, step: 97 / 281, loss: 1.7823393240417402\n",
      "Epoch: 0, step: 105 / 281, loss: 1.7946016629536947\n",
      "Epoch: 0, step: 113 / 281, loss: 1.804586623622253\n",
      "Epoch: 0, step: 121 / 281, loss: 1.7872062537295759\n",
      "Epoch: 0, step: 129 / 281, loss: 1.7722801626190658\n",
      "Epoch: 0, step: 137 / 281, loss: 1.7688390703967019\n",
      "Epoch: 0, step: 145 / 281, loss: 1.7726228578337309\n",
      "Epoch: 0, step: 153 / 281, loss: 1.7720017296816009\n",
      "Epoch: 0, step: 161 / 281, loss: 1.729567095914983\n",
      "Epoch: 0, step: 169 / 281, loss: 1.813664585704634\n",
      "Epoch: 0, step: 177 / 281, loss: 1.8022387005851768\n",
      "Epoch: 0, step: 185 / 281, loss: 1.7886903986737535\n",
      "Epoch: 0, step: 193 / 281, loss: 1.8301973359881287\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8650463675681632\n",
      "Epoch: 0, step: 209 / 281, loss: 1.8531410008241116\n",
      "Epoch: 0, step: 217 / 281, loss: 1.8192859809794184\n",
      "Epoch: 0, step: 225 / 281, loss: 1.8421772250864241\n",
      "Epoch: 0, step: 233 / 281, loss: 1.8374194775272337\n",
      "Epoch: 0, step: 241 / 281, loss: 1.8478320123496392\n",
      "Epoch: 0, step: 249 / 281, loss: 1.8586241671119828\n",
      "Epoch: 0, step: 257 / 281, loss: 1.851642537789586\n",
      "Epoch: 0, step: 265 / 281, loss: 1.8670091004866474\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8598554519724932\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8730702918831563\n",
      "0.3\n",
      "1.0\n",
      "Epoch: 1, step: 1 / 281, loss: 1.2080230712890625\n",
      "Epoch: 1, step: 9 / 281, loss: 1.4226460456848145\n",
      "Epoch: 1, step: 17 / 281, loss: 1.7462085380273706\n",
      "Epoch: 1, step: 25 / 281, loss: 1.6985968708992005\n",
      "Epoch: 1, step: 33 / 281, loss: 1.6554306131420713\n",
      "Epoch: 1, step: 41 / 281, loss: 1.735095137866532\n",
      "Epoch: 1, step: 49 / 281, loss: 1.7120519879521157\n",
      "Epoch: 1, step: 57 / 281, loss: 1.7641995070796264\n",
      "Epoch: 1, step: 65 / 281, loss: 1.718093097439179\n",
      "Epoch: 1, step: 73 / 281, loss: 1.7823770632074303\n",
      "Epoch: 1, step: 81 / 281, loss: 1.7717989983014117\n",
      "Epoch: 1, step: 89 / 281, loss: 1.7963215680269713\n",
      "Epoch: 1, step: 97 / 281, loss: 1.7352446033475326\n",
      "Epoch: 1, step: 105 / 281, loss: 1.6720560750791005\n",
      "Epoch: 1, step: 113 / 281, loss: 1.7164734985712355\n",
      "Epoch: 1, step: 121 / 281, loss: 1.8093441583154615\n",
      "Epoch: 1, step: 129 / 281, loss: 1.9117966993141544\n",
      "Epoch: 1, step: 137 / 281, loss: 1.917679554463303\n",
      "Epoch: 1, step: 145 / 281, loss: 1.9382521803009098\n",
      "Epoch: 1, step: 153 / 281, loss: 1.904349958292799\n",
      "Epoch: 1, step: 161 / 281, loss: 1.8984863714586875\n",
      "Epoch: 1, step: 169 / 281, loss: 1.8808328185737486\n",
      "Epoch: 1, step: 177 / 281, loss: 1.828675922111603\n",
      "Epoch: 1, step: 185 / 281, loss: 1.8255564526126191\n",
      "Epoch: 1, step: 193 / 281, loss: 1.803989867549486\n",
      "Epoch: 1, step: 201 / 281, loss: 1.7870673638819463\n",
      "Epoch: 1, step: 209 / 281, loss: 1.770161512722239\n",
      "Epoch: 1, step: 217 / 281, loss: 1.7472430271212407\n",
      "Epoch: 1, step: 225 / 281, loss: 1.7171869070000119\n",
      "Epoch: 1, step: 233 / 281, loss: 1.7169777189457365\n",
      "Epoch: 1, step: 241 / 281, loss: 1.7186900012473347\n",
      "Epoch: 1, step: 249 / 281, loss: 1.7136775334197354\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6892140907768145\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6986503168097082\n",
      "Epoch: 1, step: 273 / 281, loss: 1.706849603753387\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6964931444553293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "Epoch: 2, step: 1 / 281, loss: 0.9903404712677002\n",
      "Epoch: 2, step: 9 / 281, loss: 1.2091296911239624\n",
      "Epoch: 2, step: 17 / 281, loss: 1.2393223608241362\n",
      "Epoch: 2, step: 25 / 281, loss: 1.4782209968566895\n",
      "Epoch: 2, step: 33 / 281, loss: 1.306702633247231\n",
      "Epoch: 2, step: 41 / 281, loss: 1.8242759279361584\n",
      "Epoch: 2, step: 49 / 281, loss: 1.6870434719080827\n",
      "Epoch: 2, step: 57 / 281, loss: 1.7964918945442165\n",
      "Epoch: 2, step: 65 / 281, loss: 1.912631487617126\n",
      "Epoch: 2, step: 73 / 281, loss: 1.8508511142779702\n",
      "Epoch: 2, step: 81 / 281, loss: 1.8840244005859634\n",
      "Epoch: 2, step: 89 / 281, loss: 1.8810518161299523\n",
      "Epoch: 2, step: 97 / 281, loss: 1.924387781736777\n",
      "Epoch: 2, step: 105 / 281, loss: 1.8459877461194991\n",
      "Epoch: 2, step: 113 / 281, loss: 1.8139593773974783\n",
      "Epoch: 2, step: 121 / 281, loss: 1.7698975948016507\n",
      "Epoch: 2, step: 129 / 281, loss: 1.7190615355737449\n",
      "Epoch: 2, step: 137 / 281, loss: 1.7104708726932532\n",
      "Epoch: 2, step: 145 / 281, loss: 1.6974194407976906\n",
      "Epoch: 2, step: 153 / 281, loss: 1.6560666242163944\n",
      "Epoch: 2, step: 161 / 281, loss: 1.6456401289342353\n",
      "Epoch: 2, step: 169 / 281, loss: 1.6244895293338764\n",
      "Epoch: 2, step: 177 / 281, loss: 1.658791449868073\n",
      "Epoch: 2, step: 185 / 281, loss: 1.663755412117855\n",
      "Epoch: 2, step: 193 / 281, loss: 1.6330269659275836\n",
      "Epoch: 2, step: 201 / 281, loss: 1.647969593826811\n",
      "Epoch: 2, step: 209 / 281, loss: 1.6376671994274312\n",
      "Epoch: 2, step: 217 / 281, loss: 1.6328679201652379\n",
      "Epoch: 2, step: 225 / 281, loss: 1.6198144839207331\n",
      "Epoch: 2, step: 233 / 281, loss: 1.6200466218680272\n",
      "Epoch: 2, step: 241 / 281, loss: 1.6175446902320594\n",
      "Epoch: 2, step: 249 / 281, loss: 1.6030388390682788\n",
      "Epoch: 2, step: 257 / 281, loss: 1.5985633946578326\n",
      "Epoch: 2, step: 265 / 281, loss: 1.610979183327477\n",
      "Epoch: 2, step: 273 / 281, loss: 1.6157172444539192\n",
      "Epoch: 2, step: 281 / 281, loss: 1.6013490507293002\n",
      "1.0\n",
      "0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "# non-pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(3):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d8e9155b-23e4-452e-bf8c-060593e257b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 2.7592720985412598\n",
      "Epoch: 0, step: 9 / 281, loss: 2.0186812612745495\n",
      "Epoch: 0, step: 17 / 281, loss: 2.0448199720943676\n",
      "Epoch: 0, step: 25 / 281, loss: 1.946508674621582\n",
      "Epoch: 0, step: 33 / 281, loss: 1.8931593822710442\n",
      "Epoch: 0, step: 41 / 281, loss: 1.893749219615285\n",
      "Epoch: 0, step: 49 / 281, loss: 1.892821985848096\n",
      "Epoch: 0, step: 57 / 281, loss: 1.9896142169048912\n",
      "Epoch: 0, step: 65 / 281, loss: 1.8508722672095665\n",
      "Epoch: 0, step: 73 / 281, loss: 1.9114093437586746\n",
      "Epoch: 0, step: 81 / 281, loss: 1.9593559150342588\n",
      "Epoch: 0, step: 89 / 281, loss: 1.9997915217045987\n",
      "Epoch: 0, step: 97 / 281, loss: 1.9489044049351485\n",
      "Epoch: 0, step: 105 / 281, loss: 1.9180229425430297\n",
      "Epoch: 0, step: 113 / 281, loss: 1.9272019588841802\n",
      "Epoch: 0, step: 121 / 281, loss: 1.9498930420757326\n",
      "Epoch: 0, step: 129 / 281, loss: 1.9260694749595584\n",
      "Epoch: 0, step: 137 / 281, loss: 1.9041858955021322\n",
      "Epoch: 0, step: 145 / 281, loss: 1.9132682200135855\n",
      "Epoch: 0, step: 153 / 281, loss: 1.954425526600258\n",
      "Epoch: 0, step: 161 / 281, loss: 1.941598331706124\n",
      "Epoch: 0, step: 169 / 281, loss: 1.9296720733303996\n",
      "Epoch: 0, step: 177 / 281, loss: 1.9129598477465959\n",
      "Epoch: 0, step: 185 / 281, loss: 1.9176070490398922\n",
      "Epoch: 0, step: 193 / 281, loss: 1.9164788074443995\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8969166800750428\n",
      "Epoch: 0, step: 209 / 281, loss: 1.9015801939667698\n",
      "Epoch: 0, step: 217 / 281, loss: 1.9003200267317109\n",
      "Epoch: 0, step: 225 / 281, loss: 1.9030110602908665\n",
      "Epoch: 0, step: 233 / 281, loss: 1.9123343500456584\n",
      "Epoch: 0, step: 241 / 281, loss: 1.9053551694416901\n",
      "Epoch: 0, step: 249 / 281, loss: 1.892970606864217\n",
      "Epoch: 0, step: 257 / 281, loss: 1.883804381473519\n",
      "Epoch: 0, step: 265 / 281, loss: 1.8854630874013\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8779546916484833\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8755732964578473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "Epoch: 1, step: 1 / 281, loss: 2.830392599105835\n",
      "Epoch: 1, step: 9 / 281, loss: 1.83727731804053\n",
      "Epoch: 1, step: 17 / 281, loss: 1.517961924566942\n",
      "Epoch: 1, step: 25 / 281, loss: 1.7089318430423737\n",
      "Epoch: 1, step: 33 / 281, loss: 1.7376287480195363\n",
      "Epoch: 1, step: 41 / 281, loss: 1.6466180776677481\n",
      "Epoch: 1, step: 49 / 281, loss: 1.5208125582763128\n",
      "Epoch: 1, step: 57 / 281, loss: 1.5473935023734444\n",
      "Epoch: 1, step: 65 / 281, loss: 1.5701666919084696\n",
      "Epoch: 1, step: 73 / 281, loss: 1.5076581325433025\n",
      "Epoch: 1, step: 81 / 281, loss: 1.4787089151364785\n",
      "Epoch: 1, step: 89 / 281, loss: 1.4306895120090313\n",
      "Epoch: 1, step: 97 / 281, loss: 1.4951415943730737\n",
      "Epoch: 1, step: 105 / 281, loss: 1.4685016708714622\n",
      "Epoch: 1, step: 113 / 281, loss: 1.4720258272327154\n",
      "Epoch: 1, step: 121 / 281, loss: 1.4305070916975826\n",
      "Epoch: 1, step: 129 / 281, loss: 1.4437457232974296\n",
      "Epoch: 1, step: 137 / 281, loss: 1.465366628483264\n",
      "Epoch: 1, step: 145 / 281, loss: 1.5115189178236599\n",
      "Epoch: 1, step: 153 / 281, loss: 1.5301300992373548\n",
      "Epoch: 1, step: 161 / 281, loss: 1.5444391965866089\n",
      "Epoch: 1, step: 169 / 281, loss: 1.5663073895245614\n",
      "Epoch: 1, step: 177 / 281, loss: 1.5574320655758098\n",
      "Epoch: 1, step: 185 / 281, loss: 1.54351671321972\n",
      "Epoch: 1, step: 193 / 281, loss: 1.5572934641739247\n",
      "Epoch: 1, step: 201 / 281, loss: 1.5568074652211583\n",
      "Epoch: 1, step: 209 / 281, loss: 1.6085323102451397\n",
      "Epoch: 1, step: 217 / 281, loss: 1.6030795056424383\n",
      "Epoch: 1, step: 225 / 281, loss: 1.6284784177939098\n",
      "Epoch: 1, step: 233 / 281, loss: 1.6409472724654643\n",
      "Epoch: 1, step: 241 / 281, loss: 1.6476468774045652\n",
      "Epoch: 1, step: 249 / 281, loss: 1.6627607667541886\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6740873199724502\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6686845269967925\n",
      "Epoch: 1, step: 273 / 281, loss: 1.6495630288080418\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6336136016981457\n",
      "0.8\n",
      "0.4444444444444444\n",
      "Epoch: 2, step: 1 / 281, loss: 1.9566435813903809\n",
      "Epoch: 2, step: 9 / 281, loss: 0.6218284832106696\n",
      "Epoch: 2, step: 17 / 281, loss: 0.8591296120601541\n",
      "Epoch: 2, step: 25 / 281, loss: 0.9395977878570556\n",
      "Epoch: 2, step: 33 / 281, loss: 1.0163105690118037\n",
      "Epoch: 2, step: 41 / 281, loss: 1.1512325587796002\n",
      "Epoch: 2, step: 49 / 281, loss: 1.2716707350039969\n",
      "Epoch: 2, step: 57 / 281, loss: 1.3145540957910973\n",
      "Epoch: 2, step: 65 / 281, loss: 1.495930413557933\n",
      "Epoch: 2, step: 73 / 281, loss: 1.5464335586110207\n",
      "Epoch: 2, step: 81 / 281, loss: 1.5987218224707944\n",
      "Epoch: 2, step: 89 / 281, loss: 1.6002283618691262\n",
      "Epoch: 2, step: 97 / 281, loss: 1.499078758598603\n",
      "Epoch: 2, step: 105 / 281, loss: 1.5538509062358312\n",
      "Epoch: 2, step: 113 / 281, loss: 1.5527686787917552\n",
      "Epoch: 2, step: 121 / 281, loss: 1.5395956540649587\n",
      "Epoch: 2, step: 129 / 281, loss: 1.5586452919614406\n",
      "Epoch: 2, step: 137 / 281, loss: 1.5698779089389927\n",
      "Epoch: 2, step: 145 / 281, loss: 1.5954475385361704\n",
      "Epoch: 2, step: 153 / 281, loss: 1.618183017458791\n",
      "Epoch: 2, step: 161 / 281, loss: 1.633291520224595\n",
      "Epoch: 2, step: 169 / 281, loss: 1.640971308893706\n",
      "Epoch: 2, step: 177 / 281, loss: 1.6318805988057186\n",
      "Epoch: 2, step: 185 / 281, loss: 1.6292415940278284\n",
      "Epoch: 2, step: 193 / 281, loss: 1.6224725637874455\n",
      "Epoch: 2, step: 201 / 281, loss: 1.6479508011643567\n",
      "Epoch: 2, step: 209 / 281, loss: 1.6107231258419141\n",
      "Epoch: 2, step: 217 / 281, loss: 1.5947898429590985\n",
      "Epoch: 2, step: 225 / 281, loss: 1.5658624496393734\n",
      "Epoch: 2, step: 233 / 281, loss: 1.5498195792920089\n",
      "Epoch: 2, step: 241 / 281, loss: 1.5246574107047433\n",
      "Epoch: 2, step: 249 / 281, loss: 1.5199010464321658\n",
      "Epoch: 2, step: 257 / 281, loss: 1.4800316181164308\n",
      "Epoch: 2, step: 265 / 281, loss: 1.45627334688632\n",
      "Epoch: 2, step: 273 / 281, loss: 1.4560431795733753\n",
      "Epoch: 2, step: 281 / 281, loss: 1.4617534809318302\n",
      "0.41025641025641024\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# non-pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(3):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2844a3c0-fdd3-415e-abf5-f6c97604ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 1 / 281, loss: 1.7101575136184692\n",
      "Epoch: 0, step: 5 / 281, loss: 1.4812070608139039\n",
      "Epoch: 0, step: 9 / 281, loss: 1.3079716364542644\n",
      "Epoch: 0, step: 13 / 281, loss: 1.823077495281513\n",
      "Epoch: 0, step: 17 / 281, loss: 1.6630467527052935\n",
      "Epoch: 0, step: 21 / 281, loss: 1.8416676975431896\n",
      "Epoch: 0, step: 25 / 281, loss: 1.9523288106918335\n",
      "Epoch: 0, step: 29 / 281, loss: 2.014886194262011\n",
      "Epoch: 0, step: 33 / 281, loss: 1.8870762586593628\n",
      "Epoch: 0, step: 37 / 281, loss: 1.8546467729516931\n",
      "Epoch: 0, step: 41 / 281, loss: 1.9063204148920572\n",
      "Epoch: 0, step: 45 / 281, loss: 1.9453119436899822\n",
      "Epoch: 0, step: 49 / 281, loss: 2.035807441691963\n",
      "Epoch: 0, step: 53 / 281, loss: 1.9134045974263605\n",
      "Epoch: 0, step: 57 / 281, loss: 1.9582718485280086\n",
      "Epoch: 0, step: 61 / 281, loss: 1.9239012882357738\n",
      "Epoch: 0, step: 65 / 281, loss: 1.876353223507221\n",
      "Epoch: 0, step: 69 / 281, loss: 1.8896263388619907\n",
      "Epoch: 0, step: 73 / 281, loss: 1.8255659619422808\n",
      "Epoch: 0, step: 77 / 281, loss: 1.8008806953182468\n",
      "Epoch: 0, step: 81 / 281, loss: 1.816748367415534\n",
      "Epoch: 0, step: 85 / 281, loss: 1.8048715310938217\n",
      "Epoch: 0, step: 89 / 281, loss: 1.8487545975138633\n",
      "Epoch: 0, step: 93 / 281, loss: 1.8526088909436298\n",
      "Epoch: 0, step: 97 / 281, loss: 1.92378180543172\n",
      "Epoch: 0, step: 101 / 281, loss: 1.9093344825329166\n",
      "Epoch: 0, step: 105 / 281, loss: 1.8947493621281215\n",
      "Epoch: 0, step: 109 / 281, loss: 1.8812468511248948\n",
      "Epoch: 0, step: 113 / 281, loss: 1.8394868247276914\n",
      "Epoch: 0, step: 117 / 281, loss: 1.8500948186613555\n",
      "Epoch: 0, step: 121 / 281, loss: 1.8305239431129015\n",
      "Epoch: 0, step: 125 / 281, loss: 1.826094289779663\n",
      "Epoch: 0, step: 129 / 281, loss: 1.8408726869627487\n",
      "Epoch: 0, step: 133 / 281, loss: 1.819471292029646\n",
      "Epoch: 0, step: 137 / 281, loss: 1.808077679063282\n",
      "Epoch: 0, step: 141 / 281, loss: 1.8119060088556709\n",
      "Epoch: 0, step: 145 / 281, loss: 1.8129215495339754\n",
      "Epoch: 0, step: 149 / 281, loss: 1.804862349625402\n",
      "Epoch: 0, step: 153 / 281, loss: 1.8162116217457391\n",
      "Epoch: 0, step: 157 / 281, loss: 1.8620044600432086\n",
      "Epoch: 0, step: 161 / 281, loss: 1.8697025598206134\n",
      "Epoch: 0, step: 165 / 281, loss: 1.8779466173865578\n",
      "Epoch: 0, step: 169 / 281, loss: 1.8584536610270392\n",
      "Epoch: 0, step: 173 / 281, loss: 1.8783020993877697\n",
      "Epoch: 0, step: 177 / 281, loss: 1.8721296187848022\n",
      "Epoch: 0, step: 181 / 281, loss: 1.88144066123014\n",
      "Epoch: 0, step: 185 / 281, loss: 1.8965373960701195\n",
      "Epoch: 0, step: 189 / 281, loss: 1.897290414603299\n",
      "Epoch: 0, step: 193 / 281, loss: 1.9000454696348912\n",
      "Epoch: 0, step: 197 / 281, loss: 1.8857828221345312\n",
      "Epoch: 0, step: 201 / 281, loss: 1.8698130395281967\n",
      "Epoch: 0, step: 205 / 281, loss: 1.8747228058373056\n",
      "Epoch: 0, step: 209 / 281, loss: 1.8684669359448993\n",
      "Epoch: 0, step: 213 / 281, loss: 1.8781616046954768\n",
      "Epoch: 0, step: 217 / 281, loss: 1.8972996728760856\n",
      "Epoch: 0, step: 221 / 281, loss: 1.9091477197219884\n",
      "Epoch: 0, step: 225 / 281, loss: 1.898909486664666\n",
      "Epoch: 0, step: 229 / 281, loss: 1.8769738999516683\n",
      "Epoch: 0, step: 233 / 281, loss: 1.8721908865568464\n",
      "Epoch: 0, step: 237 / 281, loss: 1.874906787137945\n",
      "Epoch: 0, step: 241 / 281, loss: 1.8699842181937822\n",
      "Epoch: 0, step: 245 / 281, loss: 1.8699068813907858\n",
      "Epoch: 0, step: 249 / 281, loss: 1.8704833012508102\n",
      "Epoch: 0, step: 253 / 281, loss: 1.8746088926971194\n",
      "Epoch: 0, step: 257 / 281, loss: 1.868460552237841\n",
      "Epoch: 0, step: 261 / 281, loss: 1.8858801925776105\n",
      "Epoch: 0, step: 265 / 281, loss: 1.888021432228808\n",
      "Epoch: 0, step: 269 / 281, loss: 1.8917261047434186\n",
      "Epoch: 0, step: 273 / 281, loss: 1.8970803096617535\n",
      "Epoch: 0, step: 277 / 281, loss: 1.8719227161218113\n",
      "Epoch: 0, step: 281 / 281, loss: 1.8690247720246638\n",
      "0.2807017543859649\n",
      "0.8888888888888888\n",
      "Epoch: 1, step: 1 / 281, loss: 1.5805689096450806\n",
      "Epoch: 1, step: 5 / 281, loss: 2.3520138025283814\n",
      "Epoch: 1, step: 9 / 281, loss: 1.8644792238871257\n",
      "Epoch: 1, step: 13 / 281, loss: 1.9405400111125066\n",
      "Epoch: 1, step: 17 / 281, loss: 2.0066891628153183\n",
      "Epoch: 1, step: 21 / 281, loss: 1.9232813630785262\n",
      "Epoch: 1, step: 25 / 281, loss: 1.9817783546447754\n",
      "Epoch: 1, step: 29 / 281, loss: 1.9968116530056657\n",
      "Epoch: 1, step: 33 / 281, loss: 1.7690335566347295\n",
      "Epoch: 1, step: 37 / 281, loss: 1.724903670517174\n",
      "Epoch: 1, step: 41 / 281, loss: 1.7363584739405935\n",
      "Epoch: 1, step: 45 / 281, loss: 1.6664864791764153\n",
      "Epoch: 1, step: 49 / 281, loss: 1.7415786957254216\n",
      "Epoch: 1, step: 53 / 281, loss: 1.6978700745780513\n",
      "Epoch: 1, step: 57 / 281, loss: 1.6629301539638586\n",
      "Epoch: 1, step: 61 / 281, loss: 1.6321488814275773\n",
      "Epoch: 1, step: 65 / 281, loss: 1.6706989623033084\n",
      "Epoch: 1, step: 69 / 281, loss: 1.6601819650850433\n",
      "Epoch: 1, step: 73 / 281, loss: 1.5922527954186478\n",
      "Epoch: 1, step: 77 / 281, loss: 1.630484873211229\n",
      "Epoch: 1, step: 81 / 281, loss: 1.6899259086744285\n",
      "Epoch: 1, step: 85 / 281, loss: 1.7130673103472767\n",
      "Epoch: 1, step: 89 / 281, loss: 1.6769185524977994\n",
      "Epoch: 1, step: 93 / 281, loss: 1.6710193634674113\n",
      "Epoch: 1, step: 97 / 281, loss: 1.6818949251445299\n",
      "Epoch: 1, step: 101 / 281, loss: 1.6756939560470014\n",
      "Epoch: 1, step: 105 / 281, loss: 1.6679599537735894\n",
      "Epoch: 1, step: 109 / 281, loss: 1.6757546091845277\n",
      "Epoch: 1, step: 113 / 281, loss: 1.6506089518028022\n",
      "Epoch: 1, step: 117 / 281, loss: 1.6752598945401673\n",
      "Epoch: 1, step: 121 / 281, loss: 1.6495847566561266\n",
      "Epoch: 1, step: 125 / 281, loss: 1.621935699224472\n",
      "Epoch: 1, step: 129 / 281, loss: 1.6029541767382807\n",
      "Epoch: 1, step: 133 / 281, loss: 1.594612638529082\n",
      "Epoch: 1, step: 137 / 281, loss: 1.5528890201210106\n",
      "Epoch: 1, step: 141 / 281, loss: 1.5487046396055966\n",
      "Epoch: 1, step: 145 / 281, loss: 1.5707697985501126\n",
      "Epoch: 1, step: 149 / 281, loss: 1.5850393638114801\n",
      "Epoch: 1, step: 153 / 281, loss: 1.5994104507312277\n",
      "Epoch: 1, step: 157 / 281, loss: 1.5986018478870392\n",
      "Epoch: 1, step: 161 / 281, loss: 1.5790239159735093\n",
      "Epoch: 1, step: 165 / 281, loss: 1.595349197134827\n",
      "Epoch: 1, step: 169 / 281, loss: 1.6148373355879586\n",
      "Epoch: 1, step: 173 / 281, loss: 1.597403631217218\n",
      "Epoch: 1, step: 177 / 281, loss: 1.5824357926172052\n",
      "Epoch: 1, step: 181 / 281, loss: 1.5889694646247843\n",
      "Epoch: 1, step: 185 / 281, loss: 1.5809568393874813\n",
      "Epoch: 1, step: 189 / 281, loss: 1.5835322956874889\n",
      "Epoch: 1, step: 193 / 281, loss: 1.5854175419696255\n",
      "Epoch: 1, step: 197 / 281, loss: 1.5532263228433387\n",
      "Epoch: 1, step: 201 / 281, loss: 1.561250815788905\n",
      "Epoch: 1, step: 205 / 281, loss: 1.5929344027507595\n",
      "Epoch: 1, step: 209 / 281, loss: 1.5854551582530354\n",
      "Epoch: 1, step: 213 / 281, loss: 1.609870924776149\n",
      "Epoch: 1, step: 217 / 281, loss: 1.5949623973413547\n",
      "Epoch: 1, step: 221 / 281, loss: 1.5994621611019066\n",
      "Epoch: 1, step: 225 / 281, loss: 1.6134570403893789\n",
      "Epoch: 1, step: 229 / 281, loss: 1.605828330636545\n",
      "Epoch: 1, step: 233 / 281, loss: 1.6257209651204139\n",
      "Epoch: 1, step: 237 / 281, loss: 1.6223461366403957\n",
      "Epoch: 1, step: 241 / 281, loss: 1.645769751418181\n",
      "Epoch: 1, step: 245 / 281, loss: 1.6488633924601028\n",
      "Epoch: 1, step: 249 / 281, loss: 1.6472500603361782\n",
      "Epoch: 1, step: 253 / 281, loss: 1.6598360587956877\n",
      "Epoch: 1, step: 257 / 281, loss: 1.6705256498741268\n",
      "Epoch: 1, step: 261 / 281, loss: 1.6765508713393376\n",
      "Epoch: 1, step: 265 / 281, loss: 1.6644336664451742\n",
      "Epoch: 1, step: 269 / 281, loss: 1.6747311340388755\n",
      "Epoch: 1, step: 273 / 281, loss: 1.6680650042963552\n",
      "Epoch: 1, step: 277 / 281, loss: 1.665689977928189\n",
      "Epoch: 1, step: 281 / 281, loss: 1.6657074532899143\n",
      "0.8333333333333334\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# pretrain + finetune\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for epoch in range(2):\n",
    "    net.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for i, batch in enumerate(mri_dataloader_train):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(brain_img)\n",
    "        loss_calc = loss(torch.squeeze(outputs), labels.float())\n",
    "\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss_calc.item()\n",
    "        if i % 8 == 0:\n",
    "            print(f\"Epoch: {epoch}, step: {i+1} / {len(mri_dataloader_train)}, loss: {epoch_train_loss / (i+1)}\")\n",
    "\n",
    "    net.eval()\n",
    "    labels_pred = []\n",
    "    for i, batch in enumerate(mri_dataloader_test):\n",
    "        brain_img = batch['tensor'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_prob = torch.sigmoid(net(brain_img)).item()\n",
    "            if output_prob > 0.5:\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "\n",
    "    print(precision_score(y_test, labels_pred))\n",
    "    print(recall_score(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b90e2ecf-3fbf-478c-b589-137136abadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc955d-c1cc-4bbe-b1ce-b6c47fd011d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
